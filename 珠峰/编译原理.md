# 编译原理

写一个编译器，深入讲解AST。

这方面典型的代表工具：

1. acorn
2. esprima
3. estranvers
4. codegen

目的就是自己实现一套类似的工具。分词，解析语法树，遍历，转换语法树，生成代码。mpvue,taro,uniapp等核心就是编译原理。



## 目标

实现一个jsx转为js语法的编译器,先将一段jsx代码生成一个ast，并支持遍历和修改这个ast，然后将修改后的ast重新生成js代码。

将下面的jsx代码：

```jsx
<h1 id='title'><span>hello</span>world</h1>
```

它对应的使用esprima生成的ast：

```json
{
  "type": "Program",
  "body": [
    {
      "type": "ExpressionStatement",
      "expression": {
        "type": "JSXElement",
        "openingElement": {
          "type": "JSXOpeningElement",
          "name": {
            "type": "JSXIdentifier",
            "name": "h1",
          },
          "selfClosing": false,
          "attributes": [
            {
              "type": "JSXAttribute",
              "name": {
                "type": "JSXIdentifier",
                "name": "id",
              },
              "value": {
                "type": "Literal",
                "value": "title",
                "raw": "'title'",
              },
            }
          ],
        },
        "children": [
          {
            "type": "JSXElement",
            "openingElement": {
              "type": "JSXOpeningElement",
              "name": {
                "type": "JSXIdentifier",
                "name": "span",
              },
              "selfClosing": false,
              "attributes": [],
            },
            "children": [
              {
                "type": "JSXText",
                "value": "hello",
                "raw": "hello",
              }
            ],
            "closingElement": {
              "type": "JSXClosingElement",
              "name": {
                "type": "JSXIdentifier",
                "name": "span",
              },
            },
          },
          {
            "type": "JSXText",
            "value": "world",
            "raw": "world",
          }
        ],
        "closingElement": {
          "type": "JSXClosingElement",
          "name": {
            "type": "JSXIdentifier",
            "name": "h1",
          },
        },
      },
    }
  ],
  "sourceType": "module",
}
```



转为下面的js代码：

```js
React.createElement("h1", { id: "title" }, React.createElement("span", null, "hello"), "world");
```

它对应的抽象语法树：

```json
{
  "type": "Program",
  "body": [
    {
      "type": "ExpressionStatement",
      "expression": {
        "type": "CallExpression",
        "callee": {
          "type": "MemberExpression",
          "computed": false,
          "object": {
            "type": "Identifier",
            "name": "React",
          },
          "property": {
            "type": "Identifier",
            "name": "createElement",
          },
        },
        "arguments": [
          {
            "type": "Literal",
            "value": "h1",
            "raw": "\"h1\"",
          },
          {
            "type": "ObjectExpression",
            "properties": [
              {
                "type": "Property",
                "key": {
                  "type": "Identifier",
                  "name": "id",
                },
                "computed": false,
                "value": {
                  "type": "Literal",
                  "value": "title",
                  "raw": "\"title\"",
                  "range": [
                    32,
                    39
                  ]
                },
                "kind": "init",
                "method": false,
                "shorthand": false,
              }
            ],
          },
          {
            "type": "CallExpression",
            "callee": {
              "type": "MemberExpression",
              "computed": false,
              "object": {
                "type": "Identifier",
                "name": "React",
              },
              "property": {
                "type": "Identifier",
                "name": "createElement",
              },
            },
            "arguments": [
              {
                "type": "Literal",
                "value": "span",
                "raw": "\"span\"",
              },
              {
                "type": "Literal",
                "value": null,
                "raw": "null",
              },
              {
                "type": "Literal",
                "value": "hello",
                "raw": "\"hello\"",
              }
            ],
          },
          {
            "type": "Literal",
            "value": "world",
            "raw": "\"world\"",
          }
        ],
      },
    }
  ],
  "sourceType": "module",
}
```



基于状态机来实现 。



## 编译器工作流

- 解析(Parsing)  **解析**是将最初原始的代码转换为一种更加抽象的表示(即AST)
- 转换(Transformation)  **转换**将对这个抽象的表示做一些处理,让它能做到编译器期望它做到的事情
- 代码生成(Code Generation) 接收处理之后的代码表示,然后把它转换成新的代码





### 解析

- 解析一般分成两个阶段：**词法分析(Lexical Analysis)和语法分析(Syntactic Analysis)**

  - **词法分析**接收原始代码,然后把它分割成一些被称为 `token` 的东西，这个过程是在词法分析器(Tokenizer或者Lexer)中完成的
  - Token 是一个数组，由一些代码语句的碎片组成。它们可以是数字、标签、标点符号、运算符或者其它任何东西
  - **语法分析** 接收之前生成的 `token`，把它们转换成一种抽象的表示，这种抽象的表示描述了代码语句中的每一个片段以及它们之间的关系。这被称为中间表示(intermediate representation)或抽象语法树(Abstract Syntax Tree, 缩写为AST)
  - 抽象语法树是一个嵌套程度很深的对象，用一种更容易处理的方式代表了代码本身，也能给我们更多信息

  

```js
const esprima = require('esprima');

const sourceCode = `<h1 id='title'><span>hello</span>world</h1>`;

let ast = esprima.parseModule(sourceCode, { jsx: true, tokens: true });

console.log(ast.tokens);

/**
 * esprima内部要得到抽象语法树，需要经过两步
 * 1. 把源代码进行分词，得到一个token数组，如下
 * 2. 把得到的token数组转为一个抽象语法树
 * [
    { type: 'Punctuator', value: '<' },
    { type: 'JSXIdentifier', value: 'h1' },
    { type: 'JSXIdentifier', value: 'id' },
    { type: 'Punctuator', value: '=' },
    { type: 'String', value: "'title'" },
    { type: 'Punctuator', value: '>' },
    { type: 'Punctuator', value: '<' },
    { type: 'JSXIdentifier', value: 'span' },
    { type: 'Punctuator', value: '>' },
    { type: 'JSXText', value: 'hello' },
    { type: 'Punctuator', value: '<' },
    { type: 'Punctuator', value: '/' },
    { type: 'JSXIdentifier', value: 'span' },
    { type: 'Punctuator', value: '>' },
    { type: 'JSXText', value: 'world' },
    { type: 'Punctuator', value: '<' },
    { type: 'Punctuator', value: '/' },
    { type: 'JSXIdentifier', value: 'h1' },
    { type: 'Punctuator', value: '>' }
  ]
 */

```



### 遍历

- 为了能处理所有的结点，我们需要遍历它们，使用的是深度优先遍历

```js
const esprima = require('esprima');
const estraverse = require('estraverse-fb');

const sourceCode = `<h1 id='title'><span>hello</span>world</h1>`;

let ast = esprima.parseModule(sourceCode, { jsx: true, tokens: true });

// console.log(ast);

let indent = 0;
function padding() {
  return ' '.repeat(indent);
}

estraverse.traverse(ast, {
  enter(node) {
    console.log(padding() + node.type + '进入');
    indent += 2;
  },
  leave(node) {
    console.log(padding() + node.type + '离开');
    indent -= 2;
  }
});

/**
 * Program进入
  ExpressionStatement进入
    JSXElement进入
      JSXOpeningElement进入
        JSXIdentifier进入
          JSXIdentifier离开
        JSXAttribute进入
          JSXIdentifier进入
            JSXIdentifier离开
          Literal进入
            Literal离开
          JSXAttribute离开
        JSXOpeningElement离开
      JSXClosingElement进入
        JSXIdentifier进入
          JSXIdentifier离开
        JSXClosingElement离开
      JSXElement进入
        JSXOpeningElement进入
          JSXIdentifier进入
            JSXIdentifier离开
          JSXOpeningElement离开
        JSXClosingElement进入
          JSXIdentifier进入
            JSXIdentifier离开
          JSXClosingElement离开
        JSXText进入
          JSXText离开
        JSXElement离开
      JSXText进入
        JSXText离开
      JSXElement离开
    ExpressionStatement离开
  Program离开
 */

```



### 转换

- 编译器的在遍历各个节点时进行转换,它只是把 AST 拿过来然后对它做一些修改.它可以在同种语言下操作 AST，也可以把 AST 翻译成全新的语言

-  `AST` 中有很多相似的元素，这些元素都有`type` 属性，它们被称为 `AST`结点。这些结点含有若干属性，可以用于描述 AST 的部分信息

- 当转换AST时，可以添加、移动、删除、替换这些遍历到的节点，也可以根据现有的ast生成一个全新的ast

- 访问每个节点采用的是访问器模式

- 访问者(visitor)对象中包含一些方法，可以接收不同的结点

- 当遍历 `AST` 的时候，如果遇到了匹配 `type` 的结点，可以调用 `visitor` 中的方法

  

  

  

### 代码生成

- 这个阶段做的事情有时候会和转换(transformation)重叠,但是代码生成最主要的部分还是根据 AST 来输出代码
- 代码生成有几种不同的工作方式，有些编译器将会重用之前生成的 token，有些会创建独立的代码表示，以便于线性地输出代码。但是接下来还是着重于使用之前生成好的 `AST`
- 代码生成器需要知道如何`打印`AST 中所有类型的结点，然后它会递归地调用自身，直到所有代码都被打印到一个很长的字符串中





## 词法分析

分词一般有两种方式：

1. 正则提取，使用场景受限
2. **有限状态机**

词法分析阶段不关心语法是否正确，语法分析阶段就能识别语法错误代码。

 

### 有限状态机

-   每一个状态都是一个函数,每个函数都可以接收输入和计算输出
- 函数本身没有状态,每一个函数会根据输入决定下一个状态



```js
let NUMBERS = /[0-9]/;
let tokens = [];
const Numeric = 'Numeric';
const Punctuator = 'Punctuator';

let currentToken;

function emit(token) {
  tokens.push(token);
}

function number(char) {
  if (NUMBERS.test(char)) {
    currentToken.value += char;
    return number;
  } else if (char === '+' || char === '-') {
    emit(currentToken);
    emit({ type: Punctuator, value: char });

    currentToken = { type: Numeric, value: '' };
    return number;
  }
}

// 这个函数是默认初始创建一个token { type: Numeric, value: '' }; 并进行第一次状态的分发
function start(char) {
  if (NUMBERS.test(char)) {
    currentToken = { type: Numeric, value: '' };
    return number(char); // ****
  }
  // 其他状态
}

function tokenizer(input) {
  let state = start;
  for (const char of input) {
    state = state(char);
  }
  if (currentToken.value) emit(currentToken);
}

tokenizer('10+20');
console.log(tokens);

```



```js
let NUMBERS = /[0-9]/;
let tokens = [];
const Numeric = 'Numeric';
const Punctuator = 'Punctuator';

let currentToken;

function emit(token) {
  tokens.push(token);
  currentToken = undefined;
}

// 可以理解这就是一个状态机
function start(char) {
  // 状态机的第一种情况
  if (NUMBERS.test(char)) {
    currentToken = currentToken || { type: Numeric, value: '' };
    currentToken.value += char;
    return start;
  } else if (char === '+' || char === '-') {
    emit(currentToken);
    emit({ type: Punctuator, value: char });
    currentToken = { type: Numeric, value: '' };
    return start;
  }
  // ... 状态机的其他情况
  if (currentToken) emit(currentToken);
  currentToken = undefined;
  return (char) => char;
}

function tokenizer(input) {
  let state = start;
  for (let char of input) {
    state = state(char);
  }
  if (currentToken) {
    emit(currentToken);
  }
}

tokenizer('10+20');

console.log(tokens);

/**
 * 
[
  { type: 'Numeric', value: '10' },
  { type: 'Punctuator', value: '+' },
  { type: 'Numeric', value: '20' }
]
 */
```



### 词法分析

接收代码组成的字符串，然后把它们分割成 `token` 组成的数组

```js
const {
  LeftParentheses,
  RightParentheses,
  JSXIdentifier,
  AttributeKey,
  AttributeStringValue,
  JSXText,
  BackSlash
} = require('./tokenType');

const LETTERS = /[a-z0-9]/;
let currentToken = { type: '', value: '' };

function jsxText(char) {
  if (char === '<') {
    emit(currentToken);
    emit({ type: LeftParentheses, value: '<' });
    return foundLeftParentheses;
  } else {
    currentToken.value += char;
    return jsxText;
  }
}

function foundRightParentheses(char) {
  if (char === '<') {
    emit({ type: LeftParentheses, value: '<' });
    return foundLeftParentheses;
  } else {
    currentToken = { type: JSXText, value: char };
    return jsxText;
  }
}

function tryLeaveAttribute(char) {
  if (char === ' ') {
    return attribute;
  } else if (char === '>') {
    emit({ type: RightParentheses, valuie: '>' });
    return foundRightParentheses;
  }
}

function attributeStringValue(char) {
  if (LETTERS.test(char)) {
    currentToken.value += char;
    return attributeStringValue;
  } else if (char === '"') {
    currentToken.value += '"';
    emit(currentToken);
    return tryLeaveAttribute;
  }
}

function attributeValue(char) {
  if (char === '"') {
    currentToken = { type: AttributeStringValue, value: char };
    return attributeStringValue;
  }
}

function attributeKey(char) {
  if (LETTERS.test(char)) {
    currentToken.value += char;
    return attributeKey;
  } else if (char === '=') {
    emit(currentToken);
    return attributeValue;
  }
}

function attribute(char) {
  if (LETTERS.test(char)) {
    currentToken = { type: AttributeKey, value: char };
    return attributeKey;
  }
}

function jsxIdentifier(char) {
  if (LETTERS.test(char)) {
    currentToken.value += char;
    return jsxIdentifier;
  } else if (char === ' ') {
    emit(currentToken);
    return attribute;
  } else if (char === '>') {
    emit(currentToken);
    currentToken = { type: RightParentheses, value: char };
    return foundRightParentheses;
  }
}

function foundLeftParentheses(char) {
  if (LETTERS.test(char)) {
    currentToken = { type: JSXIdentifier, value: char };
    return jsxIdentifier;
  } else if (char === '/') {
    emit({ type: BackSlash, value: '/' });
    return foundLeftParentheses;
  }
}

function start(char) {
  if (char === '<') {
    emit({ type: LeftParentheses, value: '<' });
    return foundLeftParentheses;
  }

  throw new Error('第一个字符必须是<');
}

const tokens = [];
function emit(token) {
  currentToken = { type: '', value: '' };
  tokens.push(token);
}

function tokenizer(input) {
  let state = start;
  for (const char of input) {
    state = state && state(char);
  }

  // TODO 最后再发射一次
  return tokens;
}

module.exports = {
  tokenizer
};

let sourceCode = `<h1 id="title"><span>hello</span>world</h1>`;

console.log(tokenizer(sourceCode));

/**
[
  { type: 'LeftParentheses', value: '<' },
  { type: 'JSXIdentifier', value: 'h1' },
  { type: 'AttributeKey', value: 'id' },
  { type: 'AttributeStringValue', value: '"title"' },
  { type: 'RightParentheses', valuie: '>' },
  { type: 'LeftParentheses', value: '<' },
  { type: 'JSXIdentifier', value: 'span' },
  { type: 'JSXText', value: 'hello' },
  { type: 'LeftParentheses', value: '<' },
  { type: 'BackSlash', value: '/' },
  { type: 'JSXIdentifier', value: 'span' },
  { type: 'JSXText', value: 'world' },
  { type: 'LeftParentheses', value: '<' },
  { type: 'BackSlash', value: '/' },
  { type: 'JSXIdentifier', value: 'h1' }
]
 */

```





### 语法分析

- 语法分析器接受 `token` 数组，然后把它转化为 `AST`
- 语法分析的原理和递归下降算法（Recursive Descent Parsing）
- 上下文无关文法（Context-free Grammer,CFG）的表示方式



**递归下降算法**

- 它的左边是一个非终结符 (Non-terminal)
- 右边是它的产生式(Production Rule)
- 在语法解析的过程中，灰边会被右边替代。如果替代之后还有非终结符（非token），那么继续这个替代过程，直到最后全部都是终结符(Termina)，也就是Token
- 只有终结符才可以成为 AST 的叶子节点。这个过程，也叫做推导 (Derivation)过程
- 上级文法嵌套下级文法，上级的算法调用下级的算法。表现在生成 AST 中，上级算法生成上级节点，下级算法生成下级节点。这就是下降的含义



**上下文无关文法**

- 上下文无关的意思是，无论在任何情况下，文法的推导规则都是一样的
- 规则分成两级:第一级是加法规则，第二级是乘法规则。把乘法规则作为加法规则的子规则
- 解析形成AST时，乘法节点就一定是加法节点的子节点，从而被优先计算
- 加法规则中还 递归 地又引用了加法规则



```
2+3+4
```



语法规则

```
add -> multiple|multiple + add
multiple -> NUMBER|NUMBER * multiple
```



token

```
[
    { type: 'NUMBER', value: '2' },
    { type: 'PLUS', value: '+' },
    { type: 'NUMBER', value: '3' },
    { type: 'MULTIPLY', value: '*' },
    { type: 'NUMBER', value: '4' }
]
```



```json
{
  "type": "Program",
  "body": [
    {
      "type": "ExpressionStatement",
      "expression": {
        "type": "BinaryExpression",
        "operator": "+",
        "left": {
          "type": "BinaryExpression",
          "operator": "+",
          "left": {
            "type": "Literal",
            "value": 2,
            "raw": "2",
            ]
          },
          "right": {
            "type": "Literal",
            "value": 3,
            "raw": "3",
          },
        },
        "right": {
          "type": "Literal",
          "value": 4,
          "raw": "4",
        },
      },
    }
  ],
  "sourceType": "module",
}
```



![image-20230630143152994](C:\Users\dukkha\Desktop\study-notes\珠峰\images\image-20230630143152994.png)
