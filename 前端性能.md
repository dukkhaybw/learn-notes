

## 01_浏览器组成与功能



前端性能优化的第一步并不应该是直接冲进去写代码，而是应该先把“尺子“（性能监测工具和性能指标）找出来一样。



浏览器的组成部分（简化）：

- 用户界面：展示除标签页窗口之外的其他用户界面内容。

- 浏览器引擎：用于在用户界面和渲染引擎之间传递数据。 

- 渲染引擎（浏览器内核）：负责渲染用户请求的页面内容。

  - 网络模块：负责网络请求

  - js解释器：用于解析和执行js的

  - 数据存储持久层：帮助浏览器保存各种数据

    

![img](https://i0.hdslb.com/bfs/article/2f3b7cce7785b70f308c6093616eefc05e002caf.jpg@942w_638h_progressive.webp)



当启动某个程序时，就会创建一个进程来执行任务代码，同时会为该进程分配内存空间，该应用程序的状态都保存在该内存空间里。当应用关闭时，该内存空间就会被回收。

进程可以启动更多的进程来执行任务，由于每个进程分配的内存空间是独立的，如果两个进程间需要传递某些数据，则需要通过进程间通信管道IPC来传递。

![image-20211127181948288](.\typora-user-images\image-20211127181948288.png)

很多应用程序都是多进程的结构，这样是为了避免某一个进程卡死，由于进程间相互独立，这样不会影响到整个应用程序。

进程可以将任务分成多个更细小的任务，然后通过创建多个线程，并行执行不同的任务。同一进程下的线程之间是可以直接通信共享数据的。

![image-20211127182038040](.\typora-user-images\image-20211127182038040.png)



现代浏览器也是一个多进程结构。但早期的浏览器并不是多进程的结构，而是个单进程结构。一个进程中大概有页面线程负责页面渲染和展示等，JavaScript线程执行js代码，还有其他各种线程。单进程的结构引发了很多的问题。一是不稳定，其中一个线程的卡死可能会导致整个进程出问题，比如你打开多个标签页，有一个标签页卡死，可能会导致整个浏览器无法正常运行，二是不安全，线程之间是可以共享数据，那js线程岂不是可以随意访问进程内的数据，三是不流畅，一个进程需要负责太多事情，会导致运行效率的问题。



根据进程功能不同来拆解浏览器，我们可以将它们分解为这样的结构：

- 浏览器进程：控制其他子进程的创建和销毁，负责控制浏览器标签页以外的用户界面，包括地址栏，书签，后退和前进按钮，以及负责与浏览器的其他进程协调工作。你可以把他想成一个工厂里的主管，用来协调各个进程部门。

- 网络进程：负责发起接受网络请求

- GPU进程：负责图形渲染

- 插件进程：负责控制网站使用的所有插件，例如Flash。这里插件并不是指的是Chrome市场里安装的扩展

- Extension 进程 

- 渲染器进程（浏览器内核）：负责每个页面的渲染，脚本执行和事件处理，用来控制显示tab标签内的所有内容，浏览器在默认情况下会为每个标签页都创建一个进程。（每个渲染进程中有主线程和合成线程）

  - GUI渲染线程：页面渲染，布局和绘制，当页面需要重绘和重排时，此线程就会执行

  - js引擎线程：解析，执行js脚本（V8引擎）

    上面的两个线程是互斥的。

  - 事件触发线程（EventLoop轮询处理线程）：控制事件循环

  - 事件（onClick）

  - 定时器触发线程（setTimeout）：定时任务并不是由js引擎计时，而是由定时器触发线程来计时，计时完毕后会通知事件触发线程

  - 异步HTTP请求线程（ajax(xhr) 独立线程）：浏览器有一个单独的线程处理Ajax请求，请求完毕后，如果有回调函数，则会通知事件触发线程

  - IO线程：接受其他进行发送过来的消息
  
  
  
  在执行js代码的过程中，可以在代码中写许多创建线程的代码，比如事件线程，定时器线程等。
  
  
  
  webworker线程中是无法进行dom操作的。
  
  
  
  
  ![image-20211128104549887](.\typora-user-images\image-20211128104549887.png)
  
  
  
  默认情况下，Chromium为用户访问的网站的每个实例创建一个渲染器进程。这样可以确保来自不同站点的页面是独立呈现的，并且对同一站点的单独访问也是彼此隔离的。简单来说就是访问不同站点和同一站点的不同页面都会创建新进程。
  
  在Chromium的官方文档（文档地址：https://www.chromium.org/developers/design-documents/process-models ）上，说明了Chrome一共有四种进程模型，分别是默认的Process-per-site-instance，Process-per-site-instance模型会创建更多的进程占用更多的内存空间，但确实最安全，每个tab，以及tab内的每个站点都是相互隔离互不影响的。当其中一个标签页里渲染器进程卡死，并不会影响其他标签。
  
  
  
  Process-per-site同一站点使用同一进程。
  
  Process-per-tab一个tab里的所有站点使用一个进程。
  
  Single process则会让浏览器引擎和渲染器引擎共用一个进程。
  
  该文档还说明了各个进程模型的好处和坏处。



![img](https://i0.hdslb.com/bfs/article/a866edf0f607820915960d2233987c7d965529c2.png@942w_495h_progressive.webp)



浏览器的具体进程可以在系统的任务管理器中查看：

![image-20211127174623133](.\typora-user-images\image-20211127174623133.png)



从任务管理器我们看到当前浏览器启动了哪些进程，并且每个进程的ID号，从里面还可以发现，安装的每个扩展程序，Chrome都为他们启动了一个单独的进程来运行。如果网页中嵌入了iframe，chrome会为每个iframe都创建了一个进程。那为什么为iframe也要创建单独的进程，主要还是出于安全考虑，通过多进程让当前的主站点和iframe里的站点之间隔离。



当你在地址栏输入地址时，浏览器进程的UI线程会捕捉你的输入内容，如果访问的是网址，则UI线程会启动一个网络线程来请求DNS进行域名解析接着开始连接服务器获取数据（http:  TCP握手,  https: TLS握手）。如果你的输入不是网址而是一串关键词，浏览器就会知道你是要搜索，于是就会使用你默认配置的搜索引擎来查询。

客户端在接受服务器的响应数据时，有一个slow start机制，受制于tcp连接的限制，浏览器会先收到前14kb的数据，后续才会慢慢的增加传输速度。所以对于服务器来说，能在着14kb数据中完整的展现网站可以是一个优化点。



浏览器还有一个预扫描线程，它会扫面html代码，提前将css，字体和js文件异步下载。



当网络线程获取到数据后，会通过SafeBrowsing来检查该站点的是否是恶意站点。如果是则会展示个警告页面，告诉你这个站点有安全问题，浏览器会阻止你的访问。当然你也可以强行继续访问。SafeBrowsing是谷歌内部的一套站点安全系统，通过检测该站点的数据来判断是否安全。比如通过查看该站点的ip是否在他们的黑名单内。

![img](https://i0.hdslb.com/bfs/article/5524804480db480c70e533a3cc7b69d997e4bf72.png@942w_537h_progressive.webp)



![image-20211127182824843](.\typora-user-images\image-20211127182824843.png)

当返回数据准备完毕并且安全校验通过，网络线程会通知UI线程。然后UI线程会创建一个渲染器进程来渲染页面。浏览器进程通过IPC管道将数据传递给渲染器进程，正式进入渲染流程。此时地址栏的状态更新，比如histroy更新，现在可以点击导航栏的后退。渲染器进程收到的数据，也就是html，的核心任务就是把html、js、css、img等资源渲染成用户可交互的web页面。

渲染器进程的主线程将html进行解析，构造DOM数据结构。DOM文档对象模型是浏览器对页面在其内部表示形式，是Web程序员可以通过JavaScript与之交互的数据结构和API。HTML首先经过Tokeniser标记化，通过词法分析，将输入html内容解析成多个标记，根据识别后的标记进行DOM树构造, 在 DOM树构造过程中会创建Document对象，然后以Document为根节点的DOM树不断进行修改，向其中添加各种元素。



HTML代码中往往会引入一些额外的资源，比如图片，css和js脚本等。图片和css这些资源需要通过网络下载或者从缓存中直接加载。这些资源不会阻塞html的解析，因为他们不会影响DOM的生成，**但当html解析过程中遇到script标签，将停止html解析流程，转而去加载解析并且执行js**。为什么不直接跳过js的加载和执行这一过程，等html解析完后再加载运行js？这是因为，浏览器不知道js的执行是否会改变当前页面的html的结构，如果js代码了调用document.write方法来修改html，那之前的html的解析就没有任何意义了。这也就是为什么我们一直说要把script标签要放在合适的位置，或者使用async 或defer属性来异步加载执行js。 

![image-20211127182937791](.\typora-user-images\image-20211127182937791.png)



在html解析完成后，我们就获得一个dom tree，但我们还不知道dom tree上每个节点应该长什么样。主线程需要解析css并确定每个DOM节点的

即使你没有提供自定义的css样式，浏览器也有自己的默认的样式表，比如h2的字体要比h3的大，具体默认的样式表可以在这里查看。比如这里设定了h2的默认字体大小是要大于h3的。 在知道dom结构和每个节点的样式后，我们接下来需要知道每个节点需要放在页面上的哪个位置，也就是节点的坐标，以及该节点需要占用多大的区域。 

![image-20211127183126363](.\typora-user-images\image-20211127183126363.png)





这个阶段被称为layout布局，主线程通过遍历DOM和计算好的样式来生成layout tree，layout tree上的每个节点都记录x,y坐标和边框尺寸。这里需要注意的一点是DOM Tree和layout tree并不是一一对应的，设置了display:none的节点不会出现在layout tree上，而在before伪类中添加了content值的元素，content的内容会出现在layout tree,不会出现在DOM树里。这是因为DOM 是通过html解析获得，并不关心样式。**而layout tree是根据dom tree和计算好的样式来生成，layout tree是和最后展示在屏幕上的的节点是对应的。**

![image-20211127183153686](.\typora-user-images\image-20211127183153686.png)



![image-20211127183231698](.\typora-user-images\image-20211127183231698.png)



已经知道元素的大小，形状和位置，这还不够，我们还需要做什么了呢。对了，还需要知道以什么样的顺序绘制各个节点。举例来说，z-index这个属性会影响节点绘制的层级关系。**如果我们按照dom的层级结构或者说书写的先后顺序来绘制页面，则会导致错误的渲染。**所以为了保证在屏幕上展示正确的层级，在绘制阶段，主线程遍历layout tree创建一个**绘制记录表，该表记录了绘制的顺序**。

![image-20211127183445557](.\typora-user-images\image-20211127183445557.png)





现在知道了文档的绘制顺序，终于到了该把这些信息转化成像素点显示在屏幕的时候了。那这种行为，被称为rasterizing,栅格化。Chrome最早使用了一种很简单的方式，只栅格化用户可视区域的内容，当用户滚动页面时，再栅格化更多的内容来填充缺失的部分。这种方式带来的问题显而易见，会导致展示延迟。随着不断的优化升级，现在的Chrome使用了一种更复杂的栅格化流程，叫做compositing组合。Compositing是一种将页面的各个部分分成多个图层，分别对其进行栅格化并在合成器线程compositor thread的单独线程中进行合成页面的技术。简单来说就是，页面所有的元素按照某种规则进行分图层，并把图层都栅格化好了，然后只需要把可视区的内容组合成一帧展示给用户即可。

主线程遍历layout tree生成layer tree。

当layer tree生成完毕和绘制顺序确定后，主线程将这些信息传递给compositor线程。合成器线程将每个图层栅格化。一层可能像页面的整个长度一样大，因此合成器线程将它们切分为多个图块，然后将每个图块发送给栅格线程。

栅格线程栅格化每个图块并将它们存储在GPU内存中。对图块进行栅格化后。合成器线程可以给不同的栅格线程分别优先级，比如栅格化可视区域图块的栅格线程优先处理。

当图块栅格化完成后，合成器线程将收集称为“draw quads”的图块信息，这些信息里记录了包含诸如图块在内存中的位置和在页面的哪个位置绘制图块的信息。根据这些数据合成器线程生成了一个合成器Frame。然后这个合成器frame通过IPC传送给浏览器进程，

接着浏览器进程将compositor frame传到GPU，然后GPU渲染展示到屏幕上。恭喜你，你终于看到了页面内容。当你的页面然后变化，比如你滚动了当前页面，则会生成一个新的compositor frame，新的frame再传给GPU。再次渲染到屏幕上。 



浏览器进程的网络线程请求获取到html数据和通过IPC将数据传给渲染器进程的主线程，主线程讲html解析构造DOM树，然后计算样式，根据DOM树和样式生成layout Tree，通过遍历layout tree生成绘制顺序表，然后主线程将layout Tree和绘制顺序信息一起传给合成器线程，合成器线程按规则进程分图层，并把图层分为更小的图块传给栅格线程进行栅格化，栅格化完成后，合成器线程会获得栅格线程传过来的"draw quads"图块信息，根据这些信息，合成器线程合成了一个frame，然后将该合成frame通过IPC传回给浏览器进程，浏览器进程在传到GPU进行渲染，最后就展示到你的屏幕上了。

![image-20211127183852403](.\typora-user-images\image-20211127183852403.png)

当我们改变一个尺寸位置属性时，会重新进行样式计算，布局，绘制，以及后面的所有流程。这种行为我们称为重排。

![image-20211127183927429](.\typora-user-images\image-20211127183927429.png)

当我们改变某个元素的颜色属性时，不会重新触发布局，但还是触发会样式计算和绘制，这个就是重绘。

![image-20211127184001609](.\typora-user-images\image-20211127184001609.png)



我们可以发现重排和重绘会占用主线程，还有一个东西的运行也是在主线程。对，js。既然他们都是在主线程就会出现抢占执行时间的问题。

如果你写了个不断导致重绘重排的动画，浏览器则需要在每一帧都会运行样式计算、布局和绘制的操作，我们知道当页面以每秒大于60帧的刷新率，才不会让用户感觉到页面卡顿。

**如果你在运行动画时，还有大量的js任务需要执行，因为布局绘制和js的执行都是在主线程运行的，当在一帧的时间内，布局和绘制结束后，还有剩余时间，js就会拿到主线程的使用权，如果js执行时间过长就会导致在下一帧开始时，js没有及时归还主线程，导致下一帧动画没有按时渲染，就会出现页面动画的卡顿。**

那有什么优化的手段吗？

有，第一种就是可以通过requestAnimationFrame这个api来帮助我们解决这个问题。requestAnimationFrame这个方法会在每一帧被调用，通过这个api的回调参数，我们可以知道每一帧当前还剩余的，我们可以把js运行任务分成一些小块，在时间用完前，归还主线程，

![image-20211127184325243](.\typora-user-images\image-20211127184325243.png)

react最新的渲染引擎react fiber就是用到了这个api来做了很多优化，后面我也会出一期视频专门来讲React的最新渲染引擎React Fiber。

还有第二个优化方法。刚才我们知道栅格化整个流程是不占用主线程的，只在合成器和栅格线程中运行，这就意味着它无需和js抢夺的主线程。刚才提到，如果我们反复重绘和重排，可能会导致掉帧，因为有可能会有js的执行阻塞了主线程。css中有个动画属性叫transform，通过该属性实现的动画，不会经过布局和绘制，而是直接运行在Compositor和rasterizing线程中，所以不会受到主线程中js执行的影响。更重要的是transform的动画，由于不需要经过布局绘制样式计算，所以节省了很多运算时间。可以让复杂的动画更加流畅。位置变化，宽高变化，那这些都可以使用transform来代替。 

### 浏览器应该有的功能

	网络：
		浏览器通过网络模块来下载各式各样的资源，例如html文本；javascript代码；样式表；图片；音视频文件等。
		它耗时长，且需要安全访问互联网上的资源。
	
	资源管理：
		从网络下载，或者本地获取到的资源需要有高效的机制来管理它们。
		例如如何避免重复下载，资源如何缓存
	
	网页浏览：
		浏览器的核心，最基本的功能。
		将资源转变为可视化的结果。
		
	多页面管理
	插件与管理
	账户和同步
	安全机制
	开发者工具
	...
	
	浏览器的主要功能总结:将用户输入的url转变成可视化的图像。





### 浏览器的内核(渲染引擎)	

​	它主要的作用把一切请求回来的资源变为可视化的图像。这个模块就是**浏览器内核**，通常它也被称为**渲染引擎**。
​	浏览器内核总结：

	IE---------->Trident
	Safari------>WebKit
	  WebKit本身主要是由两个小引擎构成的，
		渲染引擎“WebCore”，
		javascript解释引擎“JSCore”
			
	Chrome----->Blink（WebKit的分支引擎） 
	Opera----->Blink			
	Firefox------>Gecko



### 进程与线程

浏览器是运行在操作系统中上的一个应用程序，而每个应用程序必须至少启动一个进程来执行其任务。一个程序往往需要运行很多任务，那进程就会创建一些线程来帮助它去执行这些细小的任务。

进程是操作系统进行资源分配和调度的基本单元，可以申请和拥有计算机资源，进程是程序的基本执行实体。

线程是操作系统能够进行运算调度的最小单位，一个进程中可以并发多个线程，每条线程并行执行不同的任务。 

​	进程: 程序的一次执行会占有一片独有的内存空间.是操作系统进行资源分配和调度的基本单元。
​		一个进程中至少有一个运行的线程: 主线程,  进程启动后自动创建
​		一个进程中也可以同时运行多个线程
​		一个进程内的数据可以供其中的多个线程直接共享，多个进程之间的数据是不能直接共享的，进程之间可以通过IPC进行通信。

​	线程：是进程内的一个独立执行单元,**是操作系统CPU能够进行运算调度的最小单位**。程序运行的基本单元
​		线程池(thread pool): 保存多个线程对象的容器, 实现线程对象的反复利用

​	JS引擎是**单线程运行的**！（事件循环机制），js的主线程是单线程的。

​	同步执行的代码开启异步定时器后，将定时器交给浏览器的定时器管理模块，时间到了之后，推入任务队列，等主线线程执行完毕后，通过事件循环在任务队列中取出异步任务，放到主线程中执行。

​	cpu调度算法：

1. 先来先得

 	2. 优先级
 	3. 时间片轮转

### 现代浏览器：多进程、多线程模型
1.单进程单线程:
		当你通过浏览器打开很多页面的时候,如果其中一个页面不响应了或者崩溃了,那么,开打的所有页面都会得不到响应。
		

2.浏览器产商如何解决
	采用多进程模型,该模型可以带来的好处
	①.避免因单个页面的不响应或者崩溃影响整个浏览器的稳定性
	②.当第三方插件崩溃时,也不会影响整个浏览器的稳定性
	③.安全
	
3.浏览器到底有些什么进程

1. **Browser进程:**
	浏览器的主进程,负责浏览器界面的显示,和各个页面的管理,用户交互，提供存储
	**浏览器中所有其他类型进程的祖先,负责其他进程的的创建和销毁**
	它有且只有一个!

 2. **Renderer进程:**
    网页渲染进程,负责页面的渲染,可以有多个
    当然渲染进程的数量不一定等于你开打网页的个数

    细分：

    - css线程
    - js引擎线程
    - 事件触发线程
- 合成器线程
    - 栅格线程
3. **插件进程**

4. **GPU进程**

5. **网络进程**：主要处理网络资源加载（HTML,CSS,JS）



​	移动设备的浏览器可能不太一样:
​		Android不支持插件,所以就没有插件进程
​		GPU演化成了Browser进程的一个线程
​		Renderer进程演化成了操作系统的一个服务进程,它仍然是独立的

4.每个进程内部又有很多线程
	多线程的目的主要是保持用户界面的高度响应
	例如:**为了不让Browser进程的UI线程被其他耗时的操作(大文件的加载,本地文件读写)所阻塞,
		那么我们就把这些操作放到分线程中去处理。**
	在Renderer进程中,为了不让其他操作阻止渲染线程的高速执行,我们通常会将渲染过程【管线化】,
	利用计算机的多核优势,让渲染的不同阶段在不同的线程中执行


​	

## 02_浏览器渲染引擎与阻塞

### 一、浏览器渲染引擎

#### 主要模块

* 一个渲染引擎主要包括：**HTML解析器**，**CSS解析器**，**javascript引擎**，**布局layout模块**，**绘图模块**

  * HTML解析器：解释HTML文档的解析器，主要作用是将HTML文本解释成DOM树。
  * CSS解析器：它的作用是为HTML中的各个元素对象计算出样式信息，为布局提供基础设施
  * Javascript引擎：javascript引擎能够解释javascript代码，并通过DOM接口和CSS树接口来修改网页内容和样式信息，从而改变渲染的结果。
  * 布局（layout）：在DOM创建之后，渲染引擎将其中的元素对象同样式信息结合起来，计算他们的大小位置等布局信息，形成一个能表达这所有信息的内部表示模型（layout tree）
  * 绘图模块（paint）：使用图形库将布局计算后的各个网页的节点绘制成图像结果
* 定时器模块：管理定时器
* 网络请求模块：负责网络资源请求
* 事件响应模块：管理dom事件

  

#### 大致的渲染过程

* 浏览器渲染页面的整个过程：浏览器会从上到下解析文档。
  1. 遇见 HTML 标记，调用HTML解析器解析为对应的 token （一个token就是一个标签文本的序列化）并构建 DOM 树（就是一块内存，保存着tokens，建立它们之间的关系）。
    2. 遇见 style/link 标记调用**相应解析器**（不一定是css解析器）处理CSS标记，并构建出CSS样式树（CSSOM）。
    3. 遇见 script 标记 调用javascript引擎 处理script标记、绑定事件、修改DOM树/CSS树等
    4. 将 DOM树 与 CSS树 合并成一个layout树。
    5. 根据渲染树来渲染，以计算每个节点的几何信息（这一过程需要依赖GPU）。
    6. 最终将各个节点绘制到屏幕上。

>以上这些模块依赖很多其他的基础模块，包括要使用到网络 存储 2D/3D图像 音频视频解码器 和 图片解码器。所以渲染引擎中还会包括如何使用这些依赖模块的部分。



在控制台查看渲染过程：

​	Performance

<img src=".\typora-user-images\image-20210311235332341.png" alt="image-20210311235332341" style="zoom:80%;" />



![image-20210311235540731](.\typora-user-images\image-20210311235540731.png)

以下只是针对了页面只加载一张图片的渲染流程：

<img src=".\typora-user-images\image-20210312000323568.png" alt="image-20210312000323568" style="zoom: 80%;" />

发送请求 => 接收响应头 => 接收响应数据（正真的数据）可能要分批次接收 => 边加载边解析html结构 => HTML解析,一行行解析过程，发现有请求其他外部资源，则又发出资源请求 =>html加载解析完成浏览器继续进行布局渲染 =>稍后接收其他资源的响应头 => 接收其他资源的响应数据（图片资源大，分了数次receive  Response）=>布局渲染一部分=>接收完就Finish Loading=>布局渲染全部完成。

一次响应接收64kb大小的数据



以下是针对内部样式表（style）和一张图片的渲染过程：

![image-20210312002628755](.\typora-user-images\image-20210312002628755.png)



![image-20210312003002567](.\typora-user-images\image-20210312003002567.png)

发送请求 => 接收响应头 => 接收响应数据（正真的数据）分批次接收 接收一点解析一点（不是全部接收完再一次性解析）=>HTML解析,一行行解析过程，发现有请求其他外部资源，则又发出资源请求 => 完成加载 =>继续解析=>稍后接收其他资源的响应头 => 接收其他资源的响应数据（图片资源大，分了数次receive  Response）=>布局渲染一部分=>接收完就Finish Loading=>布局渲染全部完成。

整个解析过程中，没有出现css解析器执行的部分。**结论：**

- **style标签内的css样式由html解析器进行解析**

- **页面的style标签内部写的样式是异步解析的，不阻塞页面渲染，不阻塞DOM解析（可能产生“闪屏”）**

  闪屏：当html解析器在遇到style样式表时，会开启异步解析css样式，同时继续解析html结构，但html结构很快就解析完成而css样式还有一段时间才能解析完成，html解析器就会先将html结构交给渲染引擎进行渲染，这时页面表现为一些没有样式的标签，当css样式被异步的html解析完成后，再次交给渲染引擎进行渲染，然后加给页面元素，这中先看到基本骨架后再看到渲染后的页面的情况就是 “ 闪屏 ”。

  简单说：结构先表现在页面上，但没加样式，随着html解析器对style中css样式的解析，页面不断更新样式，导致闪烁情况。

- 浏览器加载（下载/请求）页面中引入的其他资源是异步的

这也是不建议用style写样式的原因之一。



以下是用link标签引入外部css样式表和img的情况：

<img src=".\typora-user-images\image-20210312005241781.png" alt="image-20210312005241781" style="zoom:80%;" />



![image-20210312005600731](.\typora-user-images\image-20210312005600731.png)

![image-20210312005726218](.\typora-user-images\image-20210312005726218.png)

![image-20210312005937649](.\typora-user-images\image-20210312005937649.png)

<img src=".\typora-user-images\image-20210312010256002.png" alt="image-20210312010256002" style="zoom:80%;" />

结论：

- **link的外部样式表不是由html解析器解析的，而是由css解析器解析（parse stylesheet）**
- **link引入的外部样式表css在解析的时候是同步解析，不阻塞html解析器对html结构的解析，但是会阻塞对页面结构和样式的渲染，这样就能避免“闪屏”**
- **css的解析阻塞后续js代码的执行**



以下是用link标签引入外部css样式表，图片和内部js代码的情况：

<img src=".\typora-user-images\image-20210312085756411.png" alt="image-20210312085756411" style="zoom:80%;" />

**结论：**

- **js引擎在解析执行js代码时，html解析器是无法继续往后解析DOM结构**，因为js脚本可能操作DOM结构，可能导致html解析后续的DOM结构无用
- **js引擎在解析执行js代码时，更阻塞页面的渲染**
- **js引擎在解析执行js代码前，必须等待head中的link标签引入的css解析完成后再开始js的解析执行**
- **js引擎在解析执行js代码时，阻塞后续js的解析执行**，原因是脚本之间可能存在依赖关系
- 引入外部js脚本时阻塞的时间包含下载js脚本和解析执行js脚本的时间（当遇到script标签——无defer或者async——引入外部js脚本时，会阻塞html继续解析，等js加载完成并执行完成之后再继续html解析）







面试题：浏览器在解析HTML文件时，其中的css，js如何处理？

html文件的解析是从上到下开始解析的，其中遇到style标签编写的css时，该css样式是交给html解析器会令开启一个线程去解析这部分内部样式表，同时html解析器会继续对后面的html代码进行解析，**边解析边渲染到界面上**，遇到其他外部资源就发起资源请求。其中遇到link标签引入外部样式表时，会交给CSS解析器去加载并解析，同时html解析器继续解析后面的html（不阻塞DOM解析），因为html的是边解析边渲染的（因为body的前面没有link标签引入css），所以如果将link标签放在body的底部，则上面解析的html部分会边解析边绘制到页面上，当解析到link标签后又回去请求css回来并由css解析器进行解析，将解析后的cssom和解析的dom结合计算后再次回流页面，造成性能损耗。















关于js解析执行的新补充：

代码：

![image-20211205134707513](.\typora-user-images\image-20211205134707513.png)

针对上面的代码：

在解析html时，遇到link标签，然后发出网络请求以获取css文件，同时继续解析html，由于html很少，基本立刻解析完成了，但是请求的css文件还没有回来，这时页面会等待css文件的加载并解析，然后将解析后的html和css进行结合后开始进行页面渲染。

link标签放在head中，不阻塞html解析但阻塞渲染。  

![image-20211205135225027](.\typora-user-images\image-20211205135225027.png)





代码：

![image-20211204194425528](.\typora-user-images\image-20211204194425528.png)

刚开始表现：

![image-20211204193458062](.\typora-user-images\image-20211204193458062.png)



之后再是：

![image-20211204193516994](.\typora-user-images\image-20211204193516994.png)



整个流程：

先加载并解析HTML，解析到link标签后去加载并解析css，同时继续往后解析html结构，当解析到script标签后，暂停对html的继续往后的解析，但是js并未立刻解析执行，而是等待上面的css加载并解析完成后，再开始对js的解析执行，在css加载解析完成后，还会对页面已经解析的dom部分和css结合并进行一次渲染。

![image-20211204194043662](.\typora-user-images\image-20211204194043662.png)



在css加载并解析完成后，解析执行js代码，js代码解析完成后，又开始对剩余部分的html进行解析，又开始布局和绘制了。

![image-20211204194238782](.\typora-user-images\image-20211204194238782.png)

![image-20211204194318690](.\typora-user-images\image-20211204194318690.png)





下面的代码阻塞情况同上，只是多了加载js的过程：

![image-20211204194711875](.\typora-user-images\image-20211204194711875.png)

![image-20211204194702993](.\typora-user-images\image-20211204194702993.png)



总结：

![image-20211204194935932](.\typora-user-images\image-20211204194935932.png)

从上图可以得出的新结论是：

- css在有js代码的情况下是有可能间接阻塞html的解析的（上面的案例）



### 二、阻塞渲染		

#### 1.关于css阻塞： 

​    声明：只有link引入的外部css才能够产生阻塞。
​1.style标签中的样式：
​        (1). 由html解析器进行解析；
​        (2). 不阻塞浏览器渲染（可能会产生“闪屏现象”）；
​        (3). 不阻塞DOM解析（html解析器解析是异步解析的，针对style标签中的css可以交给html解析，而页面的其他html结构可以继续被html解析器开启另一个异步解析）；

 

2.link引入的外部css样式（推荐使用的方式）：
    (1). 由CSS解析器进行解析。
    (2). 阻塞浏览器渲染(可以利用这种阻塞避免“闪屏现象”)。       
    (3). 阻塞其后面的js语句的执行

​			原因：如果后面的js的内容是获取元素的样式，如元素的宽高等，如果不等样式解析完毕后就执行js以获取css属性，则可能获取到错误的信息。      由于浏览器不知道后续的js是否会操作和获取css属性，所以一般会css样式脚本解析完成后再执行js。


​    (4). 不阻塞DOM的解析(绝大多数浏览器的工作方式)：

​			原因：DOM解析和CSS解析是两个并行的进程，浏览器解析DOM生成DOM tree ；解析CSS 生成CSS tree，两者合并生成layout tree ，再渲染页面。  



3.优化核心理念：尽可能快的提高外部css加载速度
    	(1).使用CDN节点进行外部资源加速。
	    (2).对css进行压缩(利用打包工具，比如webpack,gulp等)。
	    (3).减少http请求数，将多个css文件合并。
	    (4).优化样式表的代码



#### 2.关于js阻塞：

​    1.阻塞后续DOM解析:
​        	原因：浏览器不知道后续脚本的内容，如果先去解析了下面的DOM，而随后的js删除了后面所有的DOM，
​              那么浏览器就做了无用功，浏览器无法预估脚本里面具体做了什么操作，例如像document.write
​              这种操作，索性全部停住，等脚本执行完了，浏览器再继续向下解析DOM。	
​    2.阻塞页面渲染:
​        	原因：js中也可以给DOM设置样式，浏览器等该脚本执行完毕，渲染出一个最终结果，避免做无用功。
​    3.阻塞后续js的执行:
​            原因：维护依赖关系，例如：必须先引入jQuery再引入bootstrap
​        

#### 3.备注

【备注1】：css的解析和js的执行是互斥的（互相排斥），css解析的时候js停止执行，js执行的时候css停止解析。



【备注2】：**无论css阻塞，还是js阻塞，都不会阻塞浏览器加载外部资源（图片、视频、样式、脚本等）**
            原因：浏览器始终处于一种：“先把请求发出去”的工作模式，只要是涉及到网络请求的内容，
                无论是：图片、样式、脚本，都会先发送请求去获取资源，至于资源到本地之后什么时候用，
                由浏览器自己协调。这种做法效率很高。



【备注3】：WebKit 和 Firefox 都进行了**预解析**这项优化。在执行js脚本时，浏览器的其他线程会预解析文档的其余部分，
          找出并加载需要通过网络加载的其他资源。通过这种方式，资源可以在并行连接上加载，
          从而提高总体速度。请注意，预解析器不会修改 DOM 树




>在上述的过程中，网页在加载和渲染过程中会触发“DOMContentLoaded”和“onload”事件
>分别是在DOM树构建（解析）完成之后，以及DOM树构建完并且网页所依赖的资源都加载完之后

* 上面介绍的是一个完整的渲染过程，但现代网页很多都是动态的，这意味着在渲染完成之后，由于网页的动画或者用户的交互，浏览器其实一直在不停地重复执行渲染过程。（重绘重排），以上的数字表示的是基本顺序，这不是严格一致的，这个过程可能重复也可能交叉。



## 03_图层与重绘重排

### css图层

​	浏览器在渲染一个页面时，会将页面分为很多个图层，图层有大有小，每个图层上有一个或多个节点。
​	在渲染DOM的时候，浏览器所做的工作实际上是：

1. 获取DOM后分割为多个图层

   2. 对每个图层的节点计算样式结果		（Recalculate style--样式重计算）
   3. 为每个节点生成图形和位置			（Layout--布局，重排，回流）
   4. 将每个节点绘制填充到图层位图中		（Paint--重绘）
   5. 图层作为纹理上传至GPU
   6. 组合多个图层到页面上生成最终屏幕图像	（Composite Layers--图层重组）

### 图层创建的条件

​	**Chrome浏览器满足以下任意情况就会创建图层：**

1. 拥有具有3D变换的CSS属性

  2. 使用加速视频解码的`<video>`节点
  3. canvas节点
  4. CSS3动画的节点

  5. 拥有CSS加速属性的元素(will-change)

### 重绘(Repaint)

​	重绘是一个元素外观的改变所触发的浏览器行为，例如改变outline、背景色等属性。浏览器会根据元素的新属性重新绘制，
​	使元素呈现新的外观。重绘不会带来重新布局，所以并不一定伴随重排。
​	

需要注意的是：**重绘重排都是以图层为单位，如果图层中某个元素需要重绘，那么整个图层都需要重绘。**
所以为了提高性能，我们应该让这些“变化的东西”拥有一个自己一个图层，
不过好在绝大多数的浏览器自己会为CSS3动画的节点自动创建图层。

### 重排(Reflow 又称：回流)

​	渲染对象在创建完成并添加到渲染树时，并不包含位置和大小信息。计算这些值的过程称为布局或重排
​	

	"重绘"不一定需要"重排"，比如改变某个网页元素的颜色，就只会触发"重绘"，不会触发"重排"，因为布局没有改变。
	"重排"大多数情况下会导致"重绘"，比如改变一个网页元素的位置，就会同时触发"重排"和"重绘"，因为布局改变了。

### 触发重绘的属性

color							* background							    	* outline-color
rder-style					 * background-image				     	* outline

border-radius			  * background-position					   * outline-style
sibility					      * background-repeat						* outline-width

text-decoration			* background-size							* box-shadow

### 触发重排(回流)的属性

   * width						* top								 	* text-align
     height					  * bottom							   * overflow-y
   * padding				   * left								      * font-weight
     rgin					      * right								    * overflow
   * display					* position							  * font-family
     rder-width			   * float								   * line-height
   * border					* clear									* vertival-align
* white-space

### 常见的触发重排的操作

​	Reflow(重排) 的成本比 Repaint(重绘) 的成本高很多很多。
​	一个结点的 Reflow 很有可能导致子结点，甚至父点以及同级结点的 Reflow。
​	在一些高性能的电脑上也许还没什么，但是如果 Reflow 发生在手机上，那么这个过程是非常痛苦和耗电的。
​	

	所以，下面这些动作有很大可能会是成本比较高的。
		当你增加、删除、修改 DOM 结点时，会导致 Reflow , Repaint。
		当你移动 DOM 的位置
		当你修改 CSS 样式的时候。
		当你 Resize 窗口的时候（移动端没有这个问题，因为移动端的缩放没有影响布局视口)
		当你修改网页的默认字体时。
		【获取某些属性时(width,height...)！！！！！】
		注：display:none 会触发 reflow，而 visibility:hidden 只会触发 repaint，因为没有发生位置变化。

### 优化方案（重绘重排）

浏览器渲染页面时经历了如下“细致”的环节：

     		1. 计算需要被加载到节点上的样式结果（Recalculate style--样式重计算）
     		2. 为每个节点生成图形和位置（Layout--重排或回流）
     		3. 将每个节点填充到图层中（Paint--重绘）
     		4. 组合图层到页面上（Composite Layers--图层重组）
      如果我们需要提升性能，需要做的就是减少浏览器在运行时所需要做的工作，即：尽量减少1234步。
    
    【具体优化方案如下】：
    1.元素位置移动变换时尽量使用CSS3的transform来代替对top left等的操作
    	变换（transform）和透明度（opacity）的改变仅仅影响图层的组合
    2.【使用opacity来代替visibility】
        (1).使用visibility不触发重排，但是依然重绘。
        (2).直接使用opacity即触发重绘，又触发重排（GPU底层设计如此！）。
        (3).opacity配合图层使用，即不触发重绘也不触发重排。
            原因：
    		透明度的改变时，GPU在绘画时只是简单的降低之前已经画好的纹理的alpha值来达到效果，并不需要整体的重绘。
    		不过这个前提是这个被修改opacity本身必须是一个图层。
    3.【不要使用table布局】
    	table-cell
    4.将【多次改变样式属性的操作合并成一次】操作
    	不要一条一条地修改DOM的样式，预先定义好class，然后修改DOM的className
    5.【将DOM离线后再修改】
    	由于display属性为none的元素不在渲染树中，对隐藏的元素操作不会引发其他元素的重排。
    	如果要对一个元素进行复杂的操作时，可以先隐藏它，操作完成后再显示。这样只在隐藏和显示时触发2次重排。
    6.【利用文档碎片】(documentFragment)------vue使用了该种方式提升性能。
    7.【不要把获取某些DOM节点的属性值放在一个循环里当成循环的变量】
    	当你请求向浏览器请求一些 style信息的时候，就会让浏览器flush队列，比如：
    		1. offsetTop, offsetLeft, offsetWidth, offsetHeight
    		2. scrollTop/Left/Width/Height
    		3. clientTop/Left/Width/Height
    		4. width,height
        当你请求上面的一些属性的时候，浏览器为了给你最精确的值，需要刷新内部队列，
        因为队列中可能会有影响到这些值的操作。即使你获取元素的布局和样式信息跟最近发生或改变的布局信息无关，
        浏览器都会强行刷新渲染队列。
    8.动画实现过程中，启用GPU硬件加速:transform: tranlateZ(0)
    9.为动画元素新建图层,提高动画元素的z-index
    10.编写动画时，尽量使用如下的API

###  requestAnimationFrame----请求动画帧

1.window.requestAnimationFrame() 
    说明：该方法会告诉浏览器在下一次重绘重排之前调用你所指定的函数
    1.参数：该方法使用一个回调函数作为参数，这个回调函数会在浏览器下一次重绘之前调用。
            回调函数会被自动传入一个参数，DOMHighResTimeStamp，标识requestAnimationFrame()开始触发回调函数的当前时间

2.返回值：
        一个 long 整数，请求 ID ，是回调列表中唯一的标识。是个非零值，没别的意义。你可以传这个值给 window.cancelAnimationFrame() 以取消回调函数。

备注：若你想在浏览器下次重绘之前继续更新下一帧动画，那么回调函数自身必须再次调用window.requestAnimationFrame()

2.window.cancelAnimationFrame(requestID)
    取消一个先前通过调用window.requestAnimationFrame()方法添加到计划中的动画帧请求。
    requestID是先前调用window.requestAnimationFrame()方法时返回的值，它是一个时间标识，用法与定时器的id类似。



## 04_CDN

### 什么是CDN？工作原理是什么？

网站通常将其所有的服务器都放在同一个地方，当用户群增加时，公司就必须在多个地理位置不同的服务器上部署内容
为了缩短http请求的时间，我们应该把大量的静态资源放置的离用户近一点。

内容发布网络CDN（Content  Delivery Networks）
    CDN是一组分布在多个不同地理位置的web服务器，用于更加有效的向用户发布内容
    

基本思路：
    尽可能避开互联网上有可能影响数据传输速度和稳定性的瓶颈和环节，使内容传输的更快、更稳定。
    通过在网络各处放置节点服务器所构成的在现有的互联网基础之上的一层智能虚拟网络，
    CDN系统能够实时地根据网络流量和各节点的连接、负载状况以及到用户的距离和响应时间等综合信息
    将用户的请求重新导向离用户最近的服务节点上。

基础架构：最简单的CDN网络由一个DNS服务器和几台缓存服务器组成
    1.用户输入的url，会经过DNS解析“翻译”成对应的ip地址，从而找到CDN专用的服务器。
    2.CDN“拿到”用户的IP地址，随后和区域负载均衡设备配合，选择一台用户所属区域的区域负载均衡设备，告诉用户向这台设备发起请求。
    3.上述步骤中的“选择”依据
            (1).选择的依据包括：根据用户IP地址，判断哪一台服务器距用户最近；
            (2).根据用户所请求的URL中携带的内容名称，判断哪一台服务器上有用户所需内容；
            (3).查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。



## 05_浏览器本地存储

### 浏览器存储 



Cookie, SessionStorage, LocalStorage这三者都可以被用来在浏览器端存储数据，而且都是字符串类型的键值对！

注意：session和SessionStorage不是一个概念！在服务端有一种存储方式叫做：session会话存储，常常被简称session

session:会话
SessionStorage:浏览器端用于存储数据的容器，常常被前端人员简称为session。
session会话存储：服务器端一种存储数据的方式，常常被后端人员简称为session。



### Web Storage



SessionStorage和LocalStorage都是浏览器本地存储，统称为Web Storage，存储内容大小一般支持5-10MB
浏览器端通过 Window.sessionStorage 和 Window.localStorage 属性来实现本地存储机制。

相关API：

1. xxxxxStorage.setItem('key', 'value');
   该方法接受一个键名和值作为参数，将会把键值对添加到存储中，如果键名存在，则更新其对应的值。

2. var data = xxxxxStorage.getItem('person');
   该方法接受一个键名作为参数，返回键名对应的值。

3. xxxxxStorage.removeItem('key');
   该方法接受一个键名作为参数，并把该键名从存储中删除。

4. xxxxxStorage.clear()
   调用该方法会清空存储中的所有键名

备注：SessionStorage存储的内容会随着浏览器窗口关闭而消失。
      LocalStorage存储的内容，需要手动清除才会消失。

storage事件：	

 1. Storage对象发生变化时触发（即创建/更新/删除数据项时，Storage.clear() 只会触发一次）

2. 在同一个页面内发生的改变不会起作用

3. 在相同域名下的其他页面发生的改变才会起作用。(修改的页面不会触发事件，与它共享的页面会触发事件)
   key 	    :  修改或删除的key值，如果调用clear(),为null
   newValue    :  新设置的值，如果调用clear(),为null
   oldValue    :  调用改变前的value值,如果调用clear(),为null
   url         :  触发该脚本变化的文档的url
   storageArea :  当前的storage对象
   使用方法：
   window.addEventListener('storage',function (event) {
       //此处写具体业务逻辑
     })

   

## 06_缓存机制

### 1. 缓存理解

    1. 缓存定义:
           1. 浏览器在本地磁盘上将用户之前请求的数据存储起来，当访问者再次需要改数据的时候无需再次发送请求，直接从浏览器本地获取数据
    2. 缓存的好处:
           1. 减少请求的个数
           2. 节省带宽，避免浪费不必要的网络资源
           3. 减轻服务器压力
           4. 提高浏览器网页的加载速度，提高用户体验

### 2. 缓存分类

    1. 强缓存
           1. 不会向服务器发送请求，直接从本地缓存中获取数据
           2. 请求资源的的状态码为: 200 ok(from memory cache)
    2. 协商缓存
           1. 向服务器发送请求，服务器会根据请求头的资源判断是否命中协商缓存
           2. 如果命中，则返回304状态码通知浏览器从缓存中读取资源
    3. 强缓存 & 协商缓存的共同点
           1. 都是从浏览器端读取资源
    4. 强缓存 VS 协商缓存的不同点
       1. 强缓存不发请求给服务器
       2. 协商缓存发请求给服务器，根据服务器返回的信息决定是否使用缓存

### 3. 缓存使用示意图

![](https://s2.ax1x.com/2019/06/17/V7f829.png)

### 4. 缓存中的header参数

#### 1、强缓存的header参数

----------

    1. expires：
           1. 这是http1.0时的规范；它的值为一个绝对时间的GMT格式的时间字符串，如```Mon, 10 Jun 2015 21:31:12 GMT```，如果发送请求的时间在expires之前，那么本地缓存始终有效，否则就会发送请求到服务器来获取资源
    2. cache-control：max-age=number
           1. 这是http1.1时出现的header信息，主要是利用该字段的max-age值来进行判断，它是一个相对值；资源第一次的请求时间和Cache-Control设定的有效期，计算出一个资源过期时间，再拿这个过期时间跟当前的请求时间比较，如果请求时间在过期时间之前，就能命中缓存，否则就不行；
                  2. cache-control常用的值（做一个简单了解即可）：
         2. no-cache: 不使用本地缓存，需要使用协商缓存。先与服务器确认返回的响应是否被更改，如果之前的响应中存在Etag，那么请求的额时候会与服务器端进行验证，如果资源为被更改则使用缓存。
         3. no-store: 直接禁止游览器缓存数据，每次用户请求该资源，都会向服务器发送一个请求，每次都会下载完整的资源。
         4. public：可以被所有的用户缓存，包括终端用户和CDN等中间代理服务器。
         5. private：只能被终端用户的浏览器缓存，不允许CDN等中继缓存服务器对其缓存。
            2. <font color=red>注意：当cache-control与Expires共存的时候cache-control的优先级高</font>

#### 2、协商缓存的header参数

----------

  <font color=red> 重点：协商缓存都是由服务器来确定缓存资源是否可用的，所以客户端与服务器端要通过某种标识来进行通信，从而让服务器判断请求资源是否可以缓存访问</font>

  * Last-Modified/If-Modified-Since:二者的值都是GMT格式的时间字符串

      1.  浏览器第一次跟服务器请求一个资源，服务器在返回这个资源的同时，在respone的header加上Last-Modified的header，这个header表示这个资源在服务器上的最后修改时间
      2.  浏览器再次跟服务器请求这个资源时，在request的header上加上If-Modified-Since的header，这个header的值就是上一次请求时返回的Last-Modified的值
      3.  服务器再次收到资源请求时，根据浏览器传过来If-Modified-Since和资源在服务器上的最后修改时间判断资源是否有变化，如果没有变化则返回304 Not Modified，但是不会返回资源内容；如果有变化，就正常返回资源内容。当服务器返回304 Not Modified的响应时，response header中不会再添加Last-Modified的header，因为既然资源没有变化，那么Last-Modified也就不会改变，这是服务器返回304时的response header
      4.  浏览器收到304的响应后，就会从缓存中加载资源
      5.  如果协商缓存没有命中，浏览器直接从服务器加载资源时，Last-Modified的Header在重新加载的时候会被更新，下次请求时，If-Modified-Since会启用上次返回的Last-Modified值
      6.  图例：<img src="https://i.imgur.com/GZqqDbS.png" style="zoom:150%;" />

-----------

   * Etag/If-None-Match
     1. 这两个值是由服务器生成的每个资源的唯一标识字符串，只要资源有变化就这个值就会改变
     2. 其判断过程与Last-Modified/If-Modified-Since类似

-----------

  * 既生Last-Modified何生Etag
    1. HTTP1.1中Etag的出现主要是为了解决几个Last-Modified比较难解决的问题
    2. 一些文件也许会周期性的更改，但是他的内容并不改变(仅仅改变的修改时间)，这个时候我们并不希望客户端认为这个文件被修改了，而重新GET
    3. 某些文件修改非常频繁，比如在秒以下的时间内进行修改，(比方说1s内修改了N次)，If-Modified-Since能检查到的粒度是s级的，这种修改无法判断(或者说UNIX记录MTIME只能精确到秒)；
    4. 某些服务器不能精确的得到文件的最后修改时间。

-----------

  * 小结：

    * 利用Etag能够更加准确的控制缓存，因为Etag是服务器自动生成或者由开发者生成的对应资源在服务器端的唯一标识符。

    * Last-Modified与ETag是可以一起使用的，服务器会优先验证ETag，一致的情况下，才会继续比对Last-Modified，最后才决定是否返回304。

      

## 涉及到相关单词

* performance: 性能
* parse: 解析，编译
* Recalculate Style：重新计算样式
* layout： 布局
* Update Layer Tree：更新图层树
* paint：绘制
* Composite Layers：合成图层





## 面试

### 加载时的优化

- 第一点：减少HTTP请求
  一个完整的 HTTP 请求需要经历 DNS 查找，TCP 握手，浏览器发出 HTTP 请求，服务器接收请求，服务器处理请求并发回响应，浏览器接收响应等等一系列复杂的过程。当你请求较多时，直接体现在了消耗性能上面，这就是为什么要将多个小文件合并为一个大文件，从而减少 HTTP 请求次数的原因。

- 第二点：使用服务器端渲染
  当客户端渲染时，他是获取 HTML 文件，根据需要下载 JavaScript 文件，运行文件，生成 DOM，再渲染。这个在无形之中会拖慢我们的性能。

- 第三点：静态资源使用 CDN

  ​	CDN就是内容分发网络，它是一组分布在多个不同地理位置的 Web 服务器。我们都知道，当服务器离用户越远时，延迟越高。CDN 就是为了解决这一问题，在多个位置部署服务器，让用户离服务器更近，从而缩短请求时间。

CDN原理：

​	当用户访问一个网站时，如果没有 CDN，过程是这样的：

1. 浏览器要将域名解析为 IP 地址，所以需要向本地 DNS 发出请求。

2. 本地 DNS 依次向根服务器、顶级域名服务器、权限服务器发出请求，得到网站服务器的 IP 地址。

3. 本地 DNS 将 IP 地址发回给浏览器，浏览器向网站服务器 IP 地址发出请求并得到资源。

​	如果用户访问的网站部署了 CDN，过程是这样的：

1. 浏览器要将域名解析为 IP 地址，所以需要向本地 DNS 发出请求。

2. 本地 DNS 依次向根服务器、顶级域名服务器、权限服务器发出请求，得到全局负载均衡系统（GSLB）的 IP 地址。

3. 本地 DNS 再向 GSLB 发出请求，GSLB 的主要功能是根据本地 DNS 的 IP 地址判断用户的位置，筛选出距离用户较近的本地负载均衡系统（SLB），并将该 SLB 的 IP 地址作为结果返回给本地 DNS。

4. 本地 DNS 将 SLB 的 IP 地址发回给浏览器，浏览器向 SLB 发出请求。

5. SLB 根据浏览器请求的资源和地址，选出最优的缓存服务器发回给浏览器。

6. 浏览器再根据 SLB 发回的地址重定向到缓存服务器。

7. 如果缓存服务器有浏览器需要的资源，就将资源发回给浏览器。如果没有，就向源服务器请求资源，再发给浏览器并缓存在本地。



- 第四点：CSS 写头部，JavaScript 写底部
  所有放在 head 标签里的 CSS 和 JS 文件都会堵塞渲染。如果这些 CSS 和 JS 需要加载和解析很久的话，那么页面就空白了。所以 JS 文件要放在底部，等 HTML 解析完了再加载 JS 文件。

​    那为什么 CSS 文件还要放在头部呢？

​    因为先加载 HTML 再加载 CSS，会让用户第一时间看到的页面是没有样式的、“丑陋”的，为了避免这种情况发生，就要将 CSS 文件放在头部了。

​    另外，JS 文件也不是不可以放在头部，只要给 script 标签加上 defer 属性就可以了，异步下载，延迟执行。



- 第五点：字体图标代替图片图标
  字体图标就是将图标制作成一个字体，使用时就跟字体一样，可以设置属性，例如 font-size、color 等等，非常方便。并且字体图标是矢量图，不会失真。还有一个优点是生成的文件特别小。

- 第六点：利用缓存不重复加载相同的资源
  为了避免用户每次访问网站都得请求文件，我们可以通过添加 Expires 来控制这一行为。Expires 设置了一个时间，只要在这个时间之前，浏览器都不会请求文件，而是直接使用缓存。

- 第七点：图片优化
  这里分为几个小点，首先是：图片延迟加载；就是在页面中，先不给图片设置路径，只有当图片出现在浏览器的可视区域时，才去加载真正的图片，这就是延迟加载。对于图片很多的网站来说，一次性加载全部图片，会对用户体验造成很大的影响，所以需要使用图片延迟加载。第二个就是：降低图片质量；图片100% 的质量和 90% 的质量通常看不出来区别，尤其是用来当背景图的时候。我们可以在用 PS 切背景图时， 将图片切成 JPG 格式，并且将它压缩到 60% 的质量，这样基本看不出来区别。第三个就是：尽可能利用 CSS3 效果代替图片；有很多图片使用 CSS 效果（渐变、阴影等）就能画出来，这种情况选择 CSS3 效果更好。因为代码大小通常是图片大小的几分之一甚至几十分之一。最后一个就是，使用雪碧图，相信大家也都明白。

- 第八点：通过 webpack 按需加载代码
  懒加载或者按需加载，是一种很好的优化网页或应用的方式。这种方式实际上是先把你的代码在一些逻辑断点处分离开，然后在一些代码块中完成某些操作后，立即引用或即将引用另外一些新的代码块。这样加快了应用的初始加载速度，减轻了它的总体体积，因为某些代码块可能永远不会被加载。

### 运行时的优化

第一点：减少重绘重排

​	用 JavaScript 修改样式时，最好不要直接写样式，而是替换 class 来改变样式。再一个就是，如果要对 DOM 元素执行一系列操作，可以将 DOM 元素脱离文档流，修改完成后，再将它带回文档。推荐使用隐藏元素（display:none）或文档碎片，都能很好的实现这个方案。

第二点：使用事件委托

​	事件委托利用了事件冒泡，只指定一个事件处理程序，就可以管理某一类型的所有事件。所有用到按钮的事件（多数鼠标事件和键盘事件）都适合采用事件委托技术， 使用事件委托可以节省内存。

第三点：if-else 对比 switch

​	当判断条件数量越来越多时，越倾向于使用 switch 而不是 if-else。不过，switch 只能用于 case 值为常量的分支结构，而 if-else 更加灵活。

第四点：不要覆盖原生方法

​	无论你的 JavaScript 代码如何优化，都比不上原生方法。因为原生方法是用低级语言写的，并且被编译成机器码，成为浏览器的一部分。当原生方法可用时，尽量使用它们，特别是数学运算和 DOM 操作。

第五点：降低CSS 选择器的复杂性

​	浏览器读取选择器，遵循的原则是从选择器的右边到左边读取。所以，尽可能的降低CSS 选择器的复杂性

第六点：使用 flexbox 布局

​	在早期的 CSS 布局方式中我们能对元素实行绝对定位、相对定位或浮动定位。而现在，我们有了 flexbo布局方式，它比起早期的布局方式来说更有优势，那就是性能比较好。不过 flexbox 兼容性还是有点问题，不是所有浏览器都支持它，所以要谨慎使用。

第七点：用 transform 和 opacity 属性更改来实现动画

​	在 CSS 中，transforms 和 opacity 这两个属性更改不会触发重排与重绘，它们是可以由合成器单独处理的属性。



性能优化新总结：

问：你在前端方面做过哪些性能优化？

在做一个从零到一的项目时，性能优化是一个不断提升的过程。优化不一定非得是代码上的优化，它还包括用户体验。在优化时有一些共性问题和特殊问题。尽量说全共性问题，且尽量带上优化的工具。

1. web性能优化辅助工具：
   - Lighthouse
   - 测试网站：http://www.webpagetest.org/
2. 具体优化内容：
   1. 加载时优化：
      - 资源的压缩合并
      - 代码分割（code spliting），可以基于路由或者动态加载
      - 第三方模块放在CMD
      - 大的模块异步加载，如：Echarts可以使用require.ensure,在加载成功后再显示对应图表
      - 小的模块适当合并
      - 可以使用pefetch预加载，在分布场景中非常适用
   2. 图片优化
      - 小图标使用雪碧图， iconFont或者base64
      - 使用图片懒加载
      - webp代替其他图片格式
      - 可以使用img的srcset，根据不同分辨率显示不同尺寸图片，保证了显示效果和节省带宽
   3. css优化
      - css样式引入写在头部
      - 避免使用css表达式
      - 不适用多余的css规则
      - 避免使用行内style
   4. js优化
      - js引入写再底部
      - 使用script标签的defer属性，加载但不妨碍dom解析
      - script标签添加crossorigin属性，方便错误的收集
   5. 渲染优化
      - 尽量减少重回和重排
      - 减少对真实dom的频繁操作，可以将多次dom操作用createDocumentFragment或者innerHTML集中处理
      - 对dom进行许多操作时，先将dom隐藏（display：none），操作完成后再显示dom元素
      - 注意开启图层（will-change或者translate3d(0, 0 ,0)）
      - 动画可以借助requestAnimationFrame，不要定时器
   6. 首屏优化
      - 将首批中用不到的代码分离
      - 首屏采用服务端渲染或者预渲染
      - DNSprefetch，使用dns-prefetch减少dns查询，pc端域名发散，移动端域名收敛
      - 减少关键路径css，可以将关键的css内联，减少渲染和加载时间
   7. 打包优化
      - 拆包 extemals 和 dllPlugin
      - 提取公共包 commonChunkPlugin 或 splitChunks
      - 缩小范围，使用各种loader配置项的include或者exclude，noParse跳过文件
      - 开启缓存
      - 多线程加速 happypack 或者thead-loader
      - tree-shaking es模块分析
      - Scope Hoisting
   8. webpack长缓存优化
      - js文件使用chunkhash而不用hash
      - css文件使用contenthash，不使用chunkhash，不受js变化影响
      - 提取vendor，公共库不受业务模块变化的影响
      - 内联webpack runtime到页面，chunkid变化不影响vendor
      - 保证module id稳定，不使用数字作为模块id，改用文件内容的hash值
   9. vue优化
      - 路由懒加载懒加载
      - keep-alive缓存组件
      - 列表添加key
      - 列表事件绑定采用事件代理
      - v-if和v-for不要载同一个标签上使用
   10. react优化
       - 路由组件懒加载，使用react-loadable
       - 类组件添加shouldComponent 或者 PureComponent
       - 函数组件添加React.memo
       - 列表添加key
       - 函数组件使用hooks优化
   11. seo优化
       - 添加各种meta信息
       - 预渲染
       - 服务端渲染





### 图片滚动懒加载

懒加载：延迟按需加载。图片滚到可视区时再加载图片。

加载原理：

- 设置鼠标滚轮的滚动的事件监听（srcoll）

- 利用自定义属性，比如data-xxx来保存图片资源的路径，当我们需要加载该图片时，才将data-xxx中的src地址赋值给img的src属性取请求。

```
<img data-src='xxxxx' src='' />
```

![image-20210820235637882](.\typora-user-images\image-20210820235637882.png)

![image-20210820235649373](.\typora-user-images\image-20210820235649373.png)

情况一：

在发送完图片资源的请求后，后端将大量的数据一次性返回。接下来就是前端在拿到这些数据时，进行展示层面的优化。

其实在图片懒加载中，后端返回的时一系列的图片src地址字符串和其他部分的数据。如果循环赋值给img的src，则都会发出请求。但是这些src只要不被赋值给img 的src属性就不会发出网络请求，也就不会触发浏览器的渲染。



情况二：

后端并不是一次性将所有的数据都返回，而是采用类似分页的情况去实现。在这种情况下，前端常常是根据滚动条是否触底来决定是否发出新的请求。

需要通过三个高度数据去判断滚动条是否触底：

- 可视区高度（window.innerHeight）
- 已加载页面内容撑开的实际高度
- 文档在垂直方向已滚动的高度（Window.scrollY）

如果   文档在垂直方向已滚动的高度 + 可视区高度 => 已加载页面内容撑开的实际高度,则说明触底。

![image-20211127192745656](.\typora-user-images\image-20211127192745656.png)

![image-20211127192839399](.\typora-user-images\image-20211127192839399.png)





**jquery插件实现**

![image-20210821001654226](.\typora-user-images\image-20210821001654226.png)







其他方法实现图片懒加载能力的需要参数：

- 可视区高度（window.innerHeight）
- 图片到可视区顶部的距离（getBoundingClientRect( ).top）

如果getBoundingClientRect( ).top的值大于window.innerHeight的值，就说明图片不在可视区域，反之则在。   将图片的真正src地址设置在图片的自定义属性上，如：data-src='xxxx'

[视频](https://www.bilibili.com/video/BV1FU4y157Li?spm_id_from=333.999.0.0)

方式一：

```js
const imgs = document.querySelectorAll('img')

window.addEventListener('scroll',function(){
    [].forEach.call(imgs,function(img){
       const ImgToTop = img.getBoundingClientRect().top
       if(ImgToTop<window.innerHeight){
          const dataSrc = img.getAttribute('data-src')
          img.setAttribute('src',dataSrc)
       }
    })
})

//这种方法的问题：鼠标每次滚动都会触发事件，导致大量鼠标滚动事件被触发，这很容易导致任务堆积，即使图片已经加载了还是会不断的对图片的src进行赋值，非常消耗资源。
```

![image-20211128100646386](.\typora-user-images\image-20211128100646386.png)

![image-20211128100726740](.\typora-user-images\image-20211128100726740.png)

![image-20211128100618620](.\typora-user-images\image-20211128100618620.png)



方式二：利用新的API——IntersectionObserver构造函数 （交叉观察），也就是目标元素和可视区域会产生交叉区域时触发回调函数。

```js
const observer = new IntersectionObserver(callback) //该回调会在dom元素出现在可视区和移出在可视区后触发，虽然知道该回调函数的触发条件，但是在出发后，我们其实并不知道图片在可视区的具体位置（或者在触发回调函数时，我们不知道图片是否已经出现在可视区内了）


// 一个observer实例可以观察多个DOM节点元素
observer.observe(DOM元素)
observer.unobserve(DOM元素)


const callback = function(entries){
	entries.forEach(entry=>{
		if(entry.isIntersecting){
			const img = entry.target
			const dataSrc = img.getAttribute('data-src')
          	img.setAttribute('src',dataSrc)
          	observer.unobserve(img)   //当该图片被加载后，取消对该图片后续的观察
		}
	})
}

const imgs = document.querySelectorAll('img')
const observer = new IntersectionObserver(callback)
imgs.forEach(function(img){
	observer.observe(img)
})
```

entries的大致结构：

![image-20210821103554355](.\typora-user-images\image-20210821103554355.png)

entry的大致结构：

其中的isIntersecting属性表示的时该dom元素是否进入可视区中。当某个被观察元素出现在交叉可视区域内时，就会触发回调函数，回调函数的参数entries中的target属性就表示对应的dom元素。

![image-20210821103742281](.\typora-user-images\image-20210821103742281.png)





## 长列表优化

优化策略

策略一：分片渲染

策略二：虚拟列表，只渲染可视区

js的主线程是单线程的。

渲染器进程：用来控制显示tab标签内的所有内容，浏览器在默认情况下会为每个标签页都创建一个进程

- GUI渲染线程：页面渲染，解析html，css，构建DOM树和CSSOM树，布局和绘制，重绘重排都由该线程执行

- js引擎线程：执行js脚本

  上面的两个线程是互斥的。平时说单线程就是指GUI线程和js引擎线程公用的那个线程。 

- 事件触发线程（EventLoop轮询处理线程），监听事件，符合条件时把回调函数放入任务队列中

- 定时器线程（setTimeout等计时器），setInterval和setTimeout在该线程中计时完毕后，由该线程将回调函数推入任务队列中

- ajax(xhr) 线程



在从上到下执行js代码的过程中，可以在代码中写许多创建其他线程的代码，比如事件线程，定时器线程，Ajax等。webworker线程中是无法进行dom操作的。


![image-20211128104549887](.\typora-user-images\image-20211128104549887.png)



刚开始执行代码时，有js引擎线程执行js代码，其中包含同步代码和开启异步任务的代码。主线程执行完代码后（期间可能产生许多异步微任务和异步宏任务），EventLoop轮询处理线程 会先去清空微任务队列完成本轮js的执行，接下来便开始渲染新的页面布局，调用GUI线程进行渲染。渲染完成后再去宏任务队列中查看并取出一次取出一项宏任务到主线程进行执行，如此往复。

**UI渲染的时机是主线程任务执行完，微任务队列清空后，在下一个宏任务队列执行之前进行UI渲染。**

将当前js引擎线程执行完毕立即去执行的异步任务就叫微任务。将当前js引擎线程执行完后在UI渲染完成执行的异步任务叫宏任务。

**微任务是js引擎的任务而宏任务是宿主环境的任务。**

微任务中能产生其他微任务或者宏任务，而宏任务中也可以继续产生宏任务或者其他微任务。





从图中就可以通过js代码检测

```jsx
<div id='container'></div>
<script>
	let total = 100000;
    let timer = Date.now()
    for(let i=0;i<total;i++){
    	let li = document.createElement('li')
        li.innerHTML = i
        container.appendChild(li)    // 理论上每生成一个li就往页面中追加一个li，导致回流而性能开销巨大，在新版的浏览器中对此做了新的优化，就是统一处理好后一次性加到页面中
    }
                     
    console.log(Date.now()-timer)   //这句话打印的时间并不是涉及GUI线程的渲染时间，而是主线程代码执行的时间（for循环执行时间） ，当该行执行并在控制台输出时间后，页面并没有渲染完成
                     
    setTimeout(() => {
        console.log(Date.now()-timer)     // 宏任务在js执行和GUI渲染完后的下一轮事件循环中执行，所以这才是上一轮js执行加上GUI渲染的总耗时
    })
</script>
```



**分片加载：**

基于浏览器的事件环机制，在GUI线程渲染完页面后开启下一个循环插入新的一批DOM元素。

```html
<div id='container'></div>
<script>
    let total = 100000;
    let index = 0;
    let id = 0;
    function load(){
        index +=50;
        if(index<total){
            setTimeout(()=>{    //核心是将宏任务推迟到GUI渲染之后执行，分片渲染。但这样的不足是会卡顿，且滚动条的长度不断变化。
                for(let i=0;i<50;i++){
                    let li = document.createElement('li')
                    li.innerHTML = id++
                    container.appendChild(li) 
                }
                load()
            },0)
        }
    }
    load()
</script>
```



主线程执行栈代码执行完毕，其中开启一个定时器 =>  微任务队列代码执行（无）  => GUI渲染  => 事件循环机制将宏任务计时器推入主线程执行  =>  创建50个DOM并添加到页面，同时开启另一个宏任务 => 微任务队列代码执行（无）  => GUI渲染  => 下一次循环。



```html
<div id='container'></div>
<script>
    let total = 100000;
    let index = 0;
    let id = 0;
    function load(){
        index +=50;
        if(index<total){
+++         requestAnimationFrame(()=>{   //requestAnimationFrame中的回调仍就是一个宏任务
                let fragment  = document.createDocumentFragment()   // 在高版本浏览器中已经可以不用createDocumentFragment来做连续的dom操作优化了
                for(let i=0;i<50;i++){
                    let li = document.createElement('li')
                    li.innerHTML = id++
                    fragment.appendChild(li) 
                }
                container.appendChild(fragment) 
                load()
            })
        }
    }
    load()
</script>



<script>
    let index = 0,
        id = 0,
        length = 100000;
    function load() {
        index += 50;
        if (index < length) {
            // 方式一：
            // setTimeout(() => {
            //   for (let i = 0; i < 50; i++) {
            //     let li = document.createElement('li');
            //     li.innerHTML = id++;
            //     container.appendChild(li);
            //   }
            //   load();
            // }, 0);

            // 方式二：
            // requestAnimationFrame(() => {
            //   for (let i = 0; i < 50; i++) {
            //     let li = document.createElement('li');
            //     li.innerHTML = id++;
            //     container.appendChild(li);
            //   }
            //   load();
            // });

            // 方式三：兼容低版本浏览器性能优化
            requestAnimationFrame(() => {
                let fragment = document.createDocumentFragment();
                for (let i = 0; i < 50; i++) {
                    let li = document.createElement('li');
                    li.innerHTML = id++;
                    fragment.appendChild(li);
                }
                container.appendChild(fragment);
                load();
            });
        }
    }
    load();
</script>

```

分片加载的问题：导致页面DOM元素过多，造成页面的卡顿。







**虚拟列表滚动插件封装**

实际开发中的情景：开发一个类似移动端新闻类H5页面的，用户下滑到接近底部时发出Ajax请求获取新数据，追加到原有页面。这时面临的问题：用户不断下来，整个页面的DOM元素不断积累，性能很差，体验也差。

主要表现：

- 访问页面时渲染速度很慢
- 页面卡顿



要处理的问题：

- 不要不长列表数据一次性全部直接渲染到页面
- 截取所有数据中的部分数据进行展示
- 长列表数据的不可视区域使用空白占位填充
- 监听容器的滚动事件，根据滚动位置去动态的改变可视区域的内容，同时移动内容区域相对于容器顶部的距离



虚拟滚动：根据容器的 可视区域 的 列表容积数量，监听用户的滑动或者滚动事件，动态截取 长列表数据 中的 部分数据 渲染到页面上，动态的调整空白占位填充容器上下滚动区域内容，模拟原生滚动效果。

![image-20211223233831930](.\typora-user-images\image-20211223233831930.png)





只渲染当前的可视区。

vue中的插件：vue-virtual-scroll-list

两种模式：

模式一：直到列表项中每一项具体的高度 











## 浏览器渲染原理和性能优化（姜文）

掌握浏览器渲染流程就能很好的理解性能优化。

浏览器是一个多进程多线程的应用软件。



浏览器中的5个进程（重点的5个）

- 浏览器进程：负责界面显示，用户交互，子进程管理，提供存储等
- 渲染进程：每个页卡都有单独的渲染进程，核心用于渲染页面
- 网络进程：主要处理网络资源加载（html，css，js等）
- GPU进程：3d绘制，性能提高
- 插件进程：浏览器中安装的插件



![image-20211204154405870](.\typora-user-images\image-20211204154405870.png)

**网络资源请求**

**进程角度：**

在浏览器进程中输入URL，浏览器进程会准备渲染进程用于渲染页面。网络进程加载资源，并将加载的资源交给渲染进程来处理。解析页面，加载页面中所需资源。渲染完毕展示结果。进程间通信使用IPC通信。

**网络角度：**

用户输入URL地址，浏览器先查询对应的URL的缓存，检测缓存是否过期，如果没有过期，则直接返回缓存结果中的内容。如果过期或者没有缓存，查看域名是否解析过，有则直接用，没有则通过DNS去进行域名解析服务，将域名转为ip地址，DNS是基于UDP协议。

DNS使用UDP协议的原因：因为解析的过程中，涉及到服务器的查找（涉及一级域名，二级域名等），查找的过程是迭代查找的，如果采用TCP协议的话，每经过一个域名服务器就需要进行一次三次握手，速度慢。而UDP是不面向连接的，速度快，丢包再传。

如果请求是HTTPS会进行SSL协商，保证数据的安全性。

解析到ip后，使用ip+端口号来进行寻址，并将请求资源进行排队等待。一个域名，在http1.1中最多可以建立6个TCP连接，同一时间最多能发送6个http请求。

请求资源在排队中，服务器和客户端进行tcp创建连接用于传输，涉及拆包，标序。

发送排队中的HTTP请求

http1.1中tcp连接默认不会断开，keep-alive。301，302会进行重定向。304的是走浏览器缓存。

服务器响应结果

![image-20211204175054491](.\typora-user-images\image-20211204175054491.png)

Queuing：请求发送前会根据优先级进行排队，同时每个域名最多处理6个TCP连接，超过的也会进行排队，并且分配磁盘空间时也会消耗一定时间

Stalled：请求发出前的等待时间（处理代理，链接复用）

DNS lookup：查询DNS的时间

initial connection：建立TCP链接的时间

SSL：SSl握手时间（ssl协商）

Request Sent：请求发送时间

Waiting（TTFB）：等待响应的时间，等待返回首个字节的时间

Content Download：用于下载响应的时间



**HTTP发展**

HTTP/0.9：在传输过程中没有请求头和请求体，服务器响应没有返回头信息，内容采用ASCII字符流只能进行传输HTML

HTTP/1.0：增加了请求头和响应头，实现多类型资源的传输，每次发完请求都会断开链接，其他请求再次创建TCP链接，性能不好

HTTP/1.1：默认开启持久链接，在一个TCP连接上可以传输多个HTTP请求，采用管线化的方式（每个域名最多维护6个TCP持久连接）有队头阻塞问题（服务器需要按照顺序依次处理请求）。完美支持数据分块传输（chunk transfer），并引入客户端cookie机制，安全机制等

HTTP/2.0：解决网络带宽使用率低（TCP慢启动，多个TCP竞争带宽，队头阻塞），采用多路复用机制（一个域名使用一个TCP长链接来提供多个请求，通过二进制分帧层来实现）。头部压缩（HPACK）以及服务端推送

HTTP/3.0：解决TCP队头阻塞问题，采用QUIC协议。QUIC协议是基于UDP的（不足是：支持和部署存在问题）

HTTP明文传输，在传输过程中会经历路由器，运营商等环节，数据有可能被窃取和篡改（安全问题）





http1.1：

![image-20211205115718452](.\typora-user-images\image-20211205115718452.png)

![image-20211205115913135](.\typora-user-images\image-20211205115913135.png)



http2.0:

![image-20211205120304194](.\typora-user-images\image-20211205120304194.png)







**浏览器渲染流程**

在浏览器中通过document.styleShheets属性可以访问到CSSOM。 document对象本身就算DOM

![image-20211204185506779](.\typora-user-images\image-20211204185506779.png)



## Perfomance API

要得到脚本运行的精确耗时，需要一个精度时间戳，传统做法是使用Date对象getTime方法，其不足之处在：

- getTime方法及Date对象的其他方法只能精确到毫秒级别

- getTime方法只能获取脚本运行过程中时间进度，无法知道一些后台事件进度，比如浏览器用了多长时间从服务器加载网页



 ![Navigation Timing Attrs](https://w3c.github.io/perf-timing-primer/images/navigation-timing-attributes.png)

![img](https://www.w3.org/TR/navigation-timing/timing-overview.png)

![image-20211205141709144](.\typora-user-images\image-20211205141709144.png)

Performance.timing对象的属性（）

| 属性                       | 含义                                                         |
| -------------------------- | ------------------------------------------------------------ |
| navigationStart            | 当前浏览器窗口的前一个网页关闭，发生unload事件时的Unix毫秒时间戳。如果没有前一个网页，则等于fetchStart属性 |
| unloadEventStart           | 如果前一个网页与当前网页属于同一个域名，则返回前一个网页的unload事件发生时的Unix毫秒时间戳。如果没有前一个网页，或者之前的网页跳转不是在同一个域名内，则返回值为0。 |
| unloadEventEnd             | 如果前一个网页与当前网页属于同一个域名，则返回前一个网页unload事件的回调函数结束时的Unix毫秒时间戳。如果没有前一个网页，或者之前的网页跳转不是在同一个域名内，则返回值为0。 |
| redirectStart              | 返回第一个HTTP跳转开始时的Unix毫秒时间戳。如果没有跳转，或者不是同一个域名内部的跳转，则返回值为0。 |
| redirectEnd                | 返回最后一个HTTP跳转结束时（即跳转回应的最后一个字节接受完成时）的Unix毫秒时间戳。如果没有跳转，或者不是同一个域名内部的跳转，则返回值为0。 |
| fetchStart                 | 返回浏览器准备使用HTTP请求读取文档时的Unix毫秒时间戳。该事件在网页查询本地缓存之前发生。 |
| domainLookupStart          | 返回域名查询开始时的Unix毫秒时间戳。如果使用持久连接，或者信息是从本地缓存获取的，则返回值等同于fetchStart属性的值。 |
| domainLookupEnd            | 返回域名查询结束时的Unix毫秒时间戳。如果使用持久连接，或者信息是从本地缓存获取的，则返回值等同于fetchStart属性的值。 |
| connectStart               | 返回HTTP请求开始向服务器发送时的Unix毫秒时间戳。如果使用持久连接（persistent connection），则返回值等同于fetchStart属性的值。 |
| connectEnd                 | 返回浏览器与服务器之间的连接建立时的Unix毫秒时间戳。如果建立的是持久连接，则返回值等同于fetchStart属性的值。连接建立指的是所有握手和认证过程全部结束。 |
| secureConnectionStart      | 返回浏览器与服务器开始安全链接的握手时的Unix毫秒时间戳。如果当前网页不要求安全连接，则返回0。 |
| requestStart               | 返回浏览器向服务器发出HTTP请求时（或开始读取本地缓存时）的Unix毫秒时间戳。 |
| responseStart              | 返回浏览器从服务器收到（或从本地缓存读取）第一个字节时的Unix毫秒时间戳。 |
| domLoading                 | 返回当前网页DOM结构开始解析时（即Document.readyState属性变为loading、相应的readystatechange事件触发时）的Unix毫秒时间戳。 |
| domInteractive             | 返回当前网页DOM结构结束解析、开始加载内嵌资源时（即Document.readyState属性变为interactive、相应的readystatechange事件触发时）的Unix毫秒时间戳。 |
| domContentLoadedEventStart | 返回当前网页DOMContentLoaded事件发生时（即DOM结构解析完毕、所有脚本开始运行时）的Unix毫秒时间戳。 |
| domContentLoadedEventEnd   | 返回当前网页所有需要执行的脚本执行完成时的Unix毫秒时间戳。   |
| domComplete                | 返回当前网页DOM结构生成时（即Document.readyState属性变为complete，以及相应的readystatechange事件发生时）的Unix毫秒时间戳。 |
| loadEventStart             | 返回当前网页load事件的回调函数开始时的Unix毫秒时间戳。如果该事件还没有发生，返回0。 |
| loadEventEnd               | 返回当前网页load事件的回调函数运行结束时的Unix毫秒时间戳。如果该事件还没有发生，返回0。 |

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200113135501969.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDEzNTEyMQ==,size_16,color_FFFFFF,t_70)



![image-20211205142531546](.\typora-user-images\image-20211205142531546.png)

![image-20211205142543432](.\typora-user-images\image-20211205142543432.png)



### 关键渲染路径

关键渲染路径：表示一渲染就一定会走的步骤。

正常的布局过程是在js执行完后进行的。当有的情况下布局步骤会在js代码执行过程中就发生。下面的两段代码就是体现了对应的情况。后者就是强制同步布局。

JavaScript强制将计算样式和布局操作提到当前的任务中。

![image-20211205152829830](.\typora-user-images\image-20211205152829830.png)



![image-20211205152724223](.\typora-user-images\image-20211205152724223.png)

![image-20211205152648641](.\typora-user-images\image-20211205152648641.png)





![image-20211205152742437](.\typora-user-images\image-20211205152742437.png)

![image-20211205152706167](.\typora-user-images\image-20211205152706167.png)





###  布局抖动

在一段js代码中，反复执行布局操作就是布局抖动。

![image-20211205153450541](.\typora-user-images\image-20211205153450541.png)

![image-20211205153502441](.\typora-user-images\image-20211205153502441.png)



减少重绘和回流

- 脱离文档流
- 渲染图片时给图片设置宽高
- 尽量使用css3动画
- 使用will-change开启单独图层









## 项目中做过什么性能优化

### 首屏加载优化

先介绍项目未进行首屏加载优化的时候，项目存在的问题。然后解决这个问题后，项目加载速度提升了多少？

如何衡量加载时间或者资源体积减少了？（不要空泛的说时间由5s->3s这种）而是以具体的页面加载指标参数说话。



TTFB

绘制方面的指标：

1. FP（First Paint）首次绘制
2. FCP（First Contentful Paint）首次内容绘制：页面从开始加载到页面开始由内容呈现时的这段耗时时长。
3. FMP（First Meaningful Paint）首次有效绘制：
4. LCP（Largest Contentful Paint）最大内容绘制



优化的方向都是为了让初次加载的资源的体积足够小。

1. 按需加载导入

2. 文件拆包和合并

3. tree-shaking

4. Gzip文件压缩

5. 第三方资源访问CDN

6. 代码本身的压缩

7. webp图片格式，图片压缩，响应式图片（几倍图），图片懒加载

8. 字体瘦身，字体子集化（用了哪些字就生成那些字对应的字体文件，借助Fontmin技术）

9. SSR，SSG

   





1. INP（Interaction to Next Paint）
2. TTI
3. TBT
4. CLS





### 缓存加载优化





### 动画卡顿优化

动画为什么会卡顿？

单线程阻塞。

主要的优化方向就是减少JS线程占用主线程时间过长。

1. 优化JavaScript的执行，减少长任务
2. 使用web worker处理计算复杂的任务
3. 采用时间切片思想对js任务进行切分
4. 多使用css动画而不用js来控制动画
5. 减少会引起重绘重排的操作
6. 使用节流防抖









### 应用状态管理优化

状态管理

视图更新的细节和原理对性能的影响







### 视图层更新优化





### 事件渲染优化





## 如何评估性能

#### 具体的性能指标





### 性能评估策略







## 如何具体落实性能优化







## 如何管理团队代码质量







# 性能优化系统课

前后端性能优化、前后端开发模式探索、Hybrid 技术体系

- 假如一名面试官问你：“你工作中是怎么做性能优化的？”会不会直接说一堆优化手段，然后被 Pass 掉？

- “线上首页打开很慢，过一会儿又好了，怎么回事？”会不会把问题归因于网络问题，结果过几天同样的问题又出现？

在问做过哪些性能优化的时候：

- 70% 的同学上来就说减少合并资源、减少请求、数据缓存这些优化手段；

- 15% 的同学会提到需要在 DevTools 下先看看首屏时间，围绕首屏来优化；

- 10%的同学会提到需要接入一个性能平台来看看现状，诊断一下；

- 5% 的同学会从前端性能体系来系统考虑性能优化。

**面试官期待的是你在什么场景下，遇到了什么性能问题，围绕什么样的性能指标，采取了哪些性能优化手段，最后取得了什么样的结果，而不仅仅是直接说采取了哪些优化手段。**

首页打开缓慢，原因有很多。前端能通过查日志就能定位平台问题，而不是停留在猜测层面。

前端有没有这样的工具呢？有，那就是性能监控平台。平台上面有各个业务的性能指标及其对应场景下的性能标准，一旦遇到性能问题，就能直接判断当前性能数据有没有问题，然后提示问题是出在前端、后端，还是网络层。

提效一般是前端工程化，具体包括编译打包发布流程、物料中心、组件化。体验领域，更多人会选择性能优化方向。


在实际工作当中，前端性能优化往往比较繁杂，防布局抖动、HTML 优化、CSS 优化、图片加载优化等，许多细节都需要顾及。

各种各样的优化思路，如缓存请求、服务端响应优化、页面解析与处理、静态资源优化等。但这些优化手段充其量只是性能优化中的一个点或几个点，很难形成一个完整的体系。

举例，你通过接入离线包来对页面进行优化，使用这种优化方式的目的是什么，围绕什么指标做的优化，优化完有什么收益。





性能优化的一个重中之重在于性能监控预警平台。通过它，可以第一时间发现问题。但这么一个重要工具，需要自己去开发。

市面上不是有类似 7 天开发一个监控平台这样的教程文章，它不行吗？不行！虽然里面提到一些方法步骤，但如何与公司现有前端性能基建对接，性能平台上包含哪些东西，需要对哪些内容做预警，应该设定什么样的预警策略，这些关键问题并没有任何资料提及。





前端指标的制定、采集和上报，在网上会看到一些资料，比如行业会议上阿里巴巴分享的采集方案，但是实践过程中，会有各种各样的坑，这个坑别人是不会分享的。

比如说，有一个搜索页面，用户在页面还没加载完成的时候，发起了搜索。这时候，你会发现采集到的首屏时间比实际的要长很多。又比如，采集到的异常数据该怎么处理，上报策略怎么设定，这些需要多次趟坑才能了解到。



性能优化中的立项是个难题，如何从业务的角度来思考性能优化的价值，并说服业务去发起这个项目，这中间有很多的方法。但这些方法你很难通过自己短期思考去获得，而在市面上也很难找到这样的知识。

比如立项正推和反推。所谓正推，就是性能线索 -> 性能问题 -> 性能优化方案 -> 性能收益 ，根据这个思路来开展立项沟通；反推是预估需要的性能收益 -> 性能优化方案 -> 性能问题 -> 性能线索，以此来确定立项。



 


从前端性能优化方法论、指标采集上报及优化手段、Hybrid 下的进阶优化、性能优化数据评估及预警，以及一线大厂性能优化体系演进五个方面讲解。

模块一：性能优化方法论。 遇到性能问题时，很多人都知道一些优化手段，但很少有人知道性能优化的系统方法论。比如，性能优化整个体系是怎样的；在页面加载过程中都有哪些性能瓶颈点；如何通过业务收益计算，说服老板和同事发起一个性能项目。



模块二：性能优化指标采集上报及常见优化手段。 在优化实战过程中，如何确定性能指标，如何采集上报，尤其是首屏时间的度量是业界的难题，为什么要使用 MutationObserver 这种方法做采集，为什么要采集所有图片的加载时间。指标采集和上报实践过程中遇到的坑。



模块三：性能问题诊断及优化手段。 如何根据性能平台问题，结合一些检查清单（如全量 VS 增量、同步 VS 异步、实时 VS 缓存、原片 VS 压缩）来诊断出性能问题；如何根据诊断清单进行优化；还有为确保后续不会随着迭代变得更差，该如何进行预警监控。



模块四：Hybrid下的进阶优化手段。 App 端内的性能优化难度会更大，跨 App 和 H5 之间，如果不了解 Hybrid 的知识，优化收益会非常有限。如WebView的优化，有时候WebView简单改一些配置，就能省掉 200ms，比辛辛苦苦优化半天还划算；又比如离线包，它需要和客户端配合好，怎么设定资源包，什么时候命中，什么时候需要跳过请求线上。



模块五：一线大厂性能优化体系演进。 介绍下当前业界的性能解决方案和演进，比如，腾讯的首屏方案和美团的首屏方案各有哪些优缺点，分别适合哪些场景；使用多端方案场景的业务，该如何优化性能，比如小程序环境中怎么设定性能指标，如何与 H5 性能体系对接；在 ReactNative 环境下如何优化渲染性能。



一般而言，一旦某个人的表现达到了“可接受”的水平，并且可以做到自动化，那么，再多“练习”几年，也不会有什么进步。甚至说，在本行业干了 20 年的医生、老师或司机，可能还稍稍比那些只干了 5 年的人差一些，原因在于，如果没有刻意地去提高，这些自动化的能力会缓慢地退化。





### 性能优化关键指标

双十一活动开始了，大家都在祈祷交易系统千万别出问题，有个同事突然发现自家的下单页面变得很慢。哪里出了问题？是网络卡顿了？还是后端接口出问题了？或者是用户的手机环境问题？

遇到这类场景判断问题，有没有想过，要是有个前端性能标准和预警监控平台就好了。一旦出现异常，直接拿平台上的数据和标准对比，就知道问题出在哪里，以及该怎么解决了。

对性能优化体系有个全面认识，然后结合具体的流程和办法教你如何快速找到问题、解决问题。



**性能优化体系**
前端性能优化一般比较琐碎繁杂，那怎么把琐碎的工作系统化？

性能优化体系具体有哪些内容？它主要包括三部分：性能优化流程、性能指标采集及上报、性能监控预警平台。



第一部分，性能优化流程
对应图中灰色部分，主要包括性能指标设定、性能标准确定、收益评估、诊断清单、优化手段、性能立项、性能实践。

其中，性能指标设定，说的是要选择什么样的指标。比如页面打开慢，想要优化它，该从哪些地方入手，优化完后怎么知道问题解决了？这些就需要明确的指标来衡量。

在设定指标之后，接下就是确定性能标准。也就是性能优化目标是怎样的，优化到什么程度合适。例如，要优化 App 里面的 H5 页面打开速度，确定的指标是秒开率，那一秒内可以打开的请求比例就是它的性能标准。

如果仅仅判断性能指标是否优化到位还好，但很多时候，为了让产品同学感觉我们是为产品服务，而不是又在造轮子，还需要关联产品目标进行收益评估。比如，列表页到详情页的转化率能不能提升？用户跳出率可不可降低？

就可以把业务代码接入性能监控预警平台，根据性能标准给出诊断清单。假如诊断出性能问题，我们就可以结合性能标准和诊断清单，确定相应的优化手段。

接着该落地实践了？不。还要有个性能项目立项。不要小视了这个环节，这是你赢得产品经理、后端同事支持，让优化顺利执行下去不可或缺的内容。许多人就是忽略了这一点，导致优化迟迟无法落地。



性能实践，即经过优化之后发起项目上线，并跟踪进行效果评估，结合场景把这些项目成果以文档或代码的形式沉淀下来，给后来者使用参考。

沉淀文档的重要性，制订优化实践，确保新人也可以执行，是优化成果得以长期保持的必要保障。比如之前有个同事通过懒加载解决了滚动列表下拉慢的问题，后来的新同事再遇到同样问题，就可以通过查看这个文档快速解决。





![image-20250310214102538](D:\learn-notes\images\image-20250310214102538.png)

对应着图中紫色部分，它的主要内容是把前面提到的性能指标以代码的形式分解落地，确保可以采集，然后在 SDK 封装后集合统计埋点，最后根据实际情况，制定上报策略。

在上报之前，我们还需要注意将一些“脏数据”（也就是明显异常的数据）丢弃掉，避免占用用户网络带宽。



对应图中橙色部分，主要是通过分析上一步采集到的性能数据，再对比性能标准进行监控。当指标超过某一监控阈值时，性能监控预警平台会通过邮件或者短信，给我们发送预警信息。

在构造上，性能监控预警平台包括：性能数据处理后台和性能可视化展现前台两部分。

其中，性能数据处理后台，主要是在性能采集数据上报到性能平台后，对数据进行预处理、数据清洗和数据计算，然后生成前台可视化所需数据。

性能可视化展现前台包括性能展示、性能监控预警，主要是对核心数据指标进行可视化展现，对性能数据波动进行监控，对超出阈值的数据给出短信或邮件报警。

最后我还想提醒你注意一点，为了确保没问题，在上线前一定要做性能专项测试，检查一下你采取的措施和性能优化预期是否一致。比如，能否正确发出请求，请求处理流程是否正确，性能平台数据能否展现。如果不一致，那就得继续优化。





比如说，现在出现了一个 6.18 活动页加载数据卡顿的性能问题，我们想要优化它，那么该怎么做？

要先确定它的性能指标及其标准是什么。因为只有设定好了性能指标，知道了它的标准，接下来我们才知道该围绕着什么来开展性能优化。但实际当中指标有那么多，比如 FPS、白屏、首屏、可操作等，最关键的是哪个？





如何设定性能关键指标？

什么样的指标值得我们关注？
根据我的经验和业界情况，要确定关键的性能指标，必须满足两点：

可衡量，就是可以通过代码来度量；

关注以用户为中心的关键结果和真实体验。

第一点好理解，无法衡量就无法优化，而第二点说的“关键结果和真实体验”是什么意思呢？

所谓关键结果，就是用户真正关心什么。举例来说，当用户进入商品详情页面，他关心的是这个商品怎么样，什么价格，具体到页面上就是商品描述、商品头图、商品价格和购买按钮这些关键信息。我们要保证无论什么情况下都能让用户看到这些信息。

而真实体验，就是用户使用产品的感受。比如当用户进入列表页，在滑动过程中，页面加载突然跳出一个弹窗，他会不会觉得烦？这就是一种真实体验。

所以，基于这两点，在性能指标方面，我选定加载、交互性和视觉稳定性这三个方向，来带你一起了解性能指标及其标准设定。

性能优化关键指标设定及标准
所谓加载，就是进入页面时，页面内容的载入过程。比如，当你打开一些网站时，你会发现，有的网站首页上的文字、图片出现很缓慢，而有的则很快，这个内容出现的过程就是加载。加载缓慢严重消耗用户的耐心，会让用户离开页面。

所谓交互，就是用户点击网站或 App 的某个功能，页面给出的回应。比如我们点击了一个“点赞”按钮，立刻给出了点赞数加一的展示，这就是交互体验好，反之如果很长时间都没回应，这就是交互体验不好。



视觉稳定性指标，叫它 CLS（Cumulative Layout Shift），也就是布局偏移量，它是指页面从一帧切换到另外一帧时，视线中不稳定元素的偏移情况。



比如，你想要购买的商品正在参加抢购活动，而且时间快要到了。在你正要点击页面链接购买的时候，原来的位置插入了一条 9.9 元包邮的商品广告。结果会怎样？你点成了那个广告商品。如果等你再返回购买的时候，你心仪商品的抢购活动结束了，你是不是很气？所以，CLS也非常重要。

在性能优化关键指标方面，目前业界主要集中在加载方面，特别是白屏时间和首屏时间。它们直接和用户体验相关，且相关的衡量标准已经达成共识。在采集方式上，除了手动采集之外，还可以自动化采集。而交互性和视觉稳定性关键指标，业界还在探索，没有统一的衡量标准，且必须手动采集。

比如交互方面，有的公司用 FID 指标 （First Input Delay，首次输入延迟）， 指标必须尽量小于 100ms，如果过长会给人页面卡顿的感觉。还有的公司使用 PSI（Perceptual Speed Index，视觉变化率），衡量标准是小于20%。

而视觉稳定性指标CLS 比较前沿，2020 年 5 月 Google 公司才发布了一篇文章关于 CLS 指标定义及相关介绍的文章。它的采集方法，除了依赖 Google 的 Lighthouse 做本地采集，目前还没有好的方案。在应用上，其他公司或者沿用 Google 的或者很少使用。

因为这两个方向还没统一的标准，接下来我就重点介绍这目前已经确定的加载关键指标，具体就是白屏时间和首屏时间的设定及其标准。



什么叫白屏时间呢？它指的是从输入内容回车（包括刷新、跳转等方式）后，到页面开始出现第一个字符的时间。这个过程包括 DNS 查询，建立 TCP 连接，发送首个HTTP请求（如果使用HTTPS还要介入 TLS 的验证时间），返回HTML文档，HTML文档 Head 解析完毕。它的标准时间是 300ms。

如果白屏时间过长，用户会认为我们的页面不可用，或者可用性差。如果超过一定时间（如 1s），用户注意力就会转移到其他页面。

哪些因素会导致白屏时间过长？原因有很多，有可能是 DNS 查询时间长，建立 TCP 请求链接太慢，或者是服务器处理请求速度太慢，客户端下载、解析、渲染时长过长，没有做 Gzip 压缩，缺乏本地离线化处理，等等。



首屏时间是怎么计算的？

首屏时间=白屏时间+渲染时间。它是指从浏览器输入地址并回车后，到首屏内容渲染完毕的时间。这期间不需要滚动鼠标或者下拉页面，否则无效。

怎么理解？下面是网站速度和性能优化 GTmetrix 官网的一个首屏时间示意图。从开始加载到第二帧时，这段时间是白屏时间，到第三帧时，首屏才开始加载，到第四帧结束时，这段时间是首屏时间。



首屏时间

在加载性能指标方面，相比于白屏时间，首屏时间更重要。为什么？

从重要性角度看，打开页面后，第一眼看到的内容一般都非常关键，比如电商的头图、商品价格、购买按钮等。这些内容即便在最恶劣的网络环境下，我们也要确保用户能看得到。

从体验完整性角度看，进入页面后先是白屏，随着第一个字符加载，到首屏内容显示结束，我们才会认为加载完毕，用户可以使用了。

白屏加载完成后，仅仅意味着页面内容开始加载，但我们还是没法完成诸如下单购买等实际操作，首屏时间结束后则可以。

首屏时间的标准，最初只是根据这个页面对时间是否敏感来判定，主要以用户平均首屏加载时间来计算，并没有详细区分 2G/3G/4G/WiFi 这些网络环境。



白屏首屏早期标准

如果一个站点对时间敏感，首屏时间在 1s 内，用户感觉会很快；如果首屏时间超过 2.5s，用户就会感觉很慢。但是在 1s 内打开页面，人们对这么短的时间并不敏感，体验不出 10ms 和 50ms 有什么差别。

但当到了 2G/3G 弱网环境，或者网络不稳定的环境（如坐火车或乘飞机时），用户联网加载的时间会特别长，严重影响整体指标。就好像 100 个穷人和马云一起，看平均资产差不多每人 5 个亿，但实际上多数人并没有那么多钱。性能也如此，前端工程师在使用过程中，越来越觉得用平均值来表示加载时间并不准确可靠。

于是，人们又开始采用中位数，做正态分布，看分位值统计。在对首屏时间进行数据分析和可视化展现时，经常用到的是 P50（50分位值）、P90（90分位值）、P99（99分位值）。它们是怎么得出的呢？以 P99 为例，我们是把所有首屏时间排序，得出排在第 99 位的首屏时间就是 P99。

不过这样处理起来还是比较麻烦，后来为了计算简单，也便于理解，我们引入了秒开率的指标，即 1s 内打开用户的占比。这个概念最早来自阿里巴巴，后来被业界普遍采用。

下面是我在带领团队做 App 性能优化项目时，按照秒开率建立的首屏时间标准。



首屏时间秒开率标准

可以说，性能指标和标准建立到这里，已经 OK了，业界能做到这一点的公司屈指可数。

但还有一个问题，首屏时间毕竟粒度太粗了，如果首屏时间长，白屏时间短，到底是哪里的问题？是数据接口的问题，还是页面渲染问题？所以我们还必须把这个指标进一步拆解细化。

首屏时间可以拆分为白屏时间、数据接口响应时间、图片加载资源等。 白屏时间前面已经提到了，数据接口响应时间可以直接从后端服务中获取，不需要前端再重复计算，我们只需取完放在性能平台即可。最后的图片资源需要我们单独采集。



好了，这一讲就到这里。希望今天的内容能让你对整个性能优化体系有个更好的认知，也相信你已经明白，学习性能优化并不仅仅是掌握一些优化技巧就可以了。特别要注意的是，进行性能优化，指标就是我们的一个抓手，首先你就要确定它的指标，然后才能根据指标去采取措施，否则就会像无头苍蝇一样乱撞，没有执行目标。

内容的最后，我想请你思考一个问题：

前面我重点讲了加载方向的指标，在交互和视觉稳定性两个方向，因为我们还在做指标设定和采集的试验，所以没展开。你有想过这个指标怎么设定和计算的吗？







## 首屏渲染过程

对 Web 前端进行性能优化需要：

1. 了解性能体系
2. 关键性能指标
3. 了解页面加载全过程
4. 影响性能的关键点、瓶颈点



- 在浏览器输入 URL 并回车后（也可能走本地资源缓存），为了把 URL 解析为 IP 地址，浏览器会向 DNS 服务器发起 DNS 查询（也可能走DNS缓存），获取 IP 地址。
- 然后通过 IP 地址找到目标服务器，发起 TCP 三次握手和 TLS 协商，从而建立起 TCP 连接。
- 在建立连接后，浏览器发起 HTTP 请求，而服务端接收到后，对请求进行响应。
- 浏览器从响应结果中拿到数据，并进行解析和渲染，最后在用户面前就出现了一个网页。

以上的整个过程大致可以分为三个阶段：

1. 客户端发起请求阶段
2. 服务端数据处理请求阶段
3. 客户端页面渲染阶段

上面三个阶段都有哪些性能瓶颈点？



### 客户端请求阶段的瓶颈点

- 是否有本地缓存

  本地缓存可以让静态资源加载更快，当客户端发起一个请求时，静态资源可以直接从客户端中获取，不需要再向服务器请求。资源缓存需要服务器进行配置（各种http请求头）。

  


  如何实现本地缓存？

  - 强缓存

    强缓存是指浏览器在加载资源时，根据请求头的 expires 和 cache-control 判断是否命中客户端缓存。如果命中，则直接从缓存读取资源，不会发请求到服务器，反之还需要走http的资源请求流程。

  - 协商缓存

    协商缓存是指，浏览器会先发送一个请求到服务器，通过 last-modified 和 etag 验证资源是否命中客户端缓存。如果命中，服务器会将这个请求返回，但不会返回这个资源的数据，依然是从缓存中读取资源。 如果没有命中，无论是资源过期或者没有相关资源，都需要向服务器发起请求，等待服务器返回这个资源。

    

- DNS查询

  每进行一次完整的 DNS 查询，都要经历UDP请求多个服务器，再到认证 DNS 服务器的过程。这中间需要时间。

  最快的是DNS 查询走缓存。同时浏览器提供了 DNS 预获取的接口，可以在打开浏览器或者 WebView 的同时就进行配置。这样真正请求时，DNS 域名解析可以检查一下浏览器缓存，一旦缓存命中，就不需要去 DNS 服务器查询了。

  

- HTTP 请求

  HTTP层面的对头阻塞问题，浏览器为保证访问速度，会默认对同一域下的资源保持一定的连接数，请求过多就会进行对http请求进行排队。

  浏览器同域名的连接数限制一般是 6 个。如果当前请求书多于 6 个，只能 6 个并发，其余的得等最先返回的请求后，才能做下一次请求。

  所以采用CDN实现域名分片也能一定程度优化这个阻塞问题。这个域名个数不是越多越好，太分散的话，又会涉及多域名之间无法缓存的问题。

  

### 服务端数据处理阶段的瓶颈点

WebServer 接收到请求后，从数据存储层取到数据，再返回给前端的过程。

服务端程序接收到 HTTP 请求后，会做一些请求参数处理以及权限校验。校验完成后，它会将请求参数发送到数据存储服务。然后服务端程序会从数据存储中取到数据，进行数据加工聚合处理，最后再通过 jsonp 或者 ajax 接口返回给前端。



本阶段的瓶颈点：

- **是否做了数据缓存处理**

  数据缓存分为三种：

  - 借助 Service Worker 的数据接口缓存

    Service Worker 是浏览器的一个高级属性，本质上是一个请求代理层，它存在的目的就是拦截和处理网络数据请求。如果没有 Service Worker，请求每次直接落到 WebServer 上，需要走一次后端数据存取链路的流程，这会延长页面打开时间。

  - 借助本地存储的接口缓存

    在一些对数据时效性要求不高的页面，第一次请求到数据后，程序将数据存储到本地存储（store 或者 localStorage、甚至客户端本身的存储），下一次请求的时候，先去缓存里面取将取数据，如果没有的话，再向服务器发起请求。

  - CDN（Content Delivery Network，内容分发网络）

    通过在网络各处放置节点服务器，构造一个智能虚拟网络，将用户的请求导向离用户最近的服务节点上获取资源文件。

  

- **是否做了 Gip 压缩**

  服务器端通过使用 Gzip，传输到浏览器端的文本类资源（有别于图片等二进制等资源）的大小可以变为原来的 1/3 左右。这样资源的下载速度会快很多，能大大提升页面的展示速度。

  

- **是否有重定向**

  重定向是指网站资源（如表单，整个站点等）迁移到其他位置后，用户访问站点时，程序自动将用户请求从一个页面转移到另外一个页面的过程。

  重定向分为三类：

  - 服务端发挥的301或者302重定向
  - META 标签实现的重定向
  - 前端 Javasript 通过window.location 实现的重定向



### 页面解析和渲染阶段的瓶颈点

当前服务端对请求响应后，客户端拿到数据，接下来就会进入解析和渲染阶段。

解析是 HTML 解析器和CSS解析器把页面内容转换为 DOM 树和 CSSOM树的过程。

DOM 树全称为 Document Object Model 即文档对象模型，它描述了标签之间的层次和结构。HTML 解析器通过词法分析获得开始和结束标签，生成相应的节点和创建节点之间的父子关系结构，直到完成 DOM 树的创建。

CSSOM 树，即 CSS 对象模型。主要描述样式集的层次和结构，HTML 解析器遇到内联的 style 标签时，会触发 CSS 解析器对样式内容进行解析，CSS 解析器遍历其中每个规则，将 CSS 规则解析浏览器可解析和处理的样式集合，最终结合浏览器里面的默认样式，汇总形成具有父子关系的 CSSOM 树。

解析完后就是渲染。主线程会计算 DOM 节点的最终样式，生成布局树。布局树会记录参与页面布局的节点和样式。完成布局后，紧跟着就是绘制。绘制就是把各个节点绘制到屏幕上的过程，绘制结果以层的方式保存。当文档中各个部分以不同的层绘制时，相互重叠时，就必须进行合成，以确保他们可以以正确的顺序绘制和展示。


这个阶段流程环节多，逻辑复杂，瓶颈点也多，比如，DOM 树构建过程，CSSOM 树生成阶段，重排和重绘过程等。



#### 构建 DOM 树的瓶颈点

HTML解析器构建 DOM 树的过程中，有三点会严重影响前端性能。

- 一个是当 HTML 标签不满足 Web 语义化时，浏览器就需要更多时间去解析 DOM 标签的含义。特别解析器是对标签的容错，比如将 `<br>` 写成了 `</br>`，又或者表格嵌套不标准，标签层次结构复杂等。遇到这些情况时，浏览器会进行语法纠错。这就会导致页面总的解析和渲染阶段需要更长的时间，严重影响页面展示性能。

- DOM 节点的数量越多，构建 DOM 树的时间就会变长，进而延长解析时间，拖慢页面展示速度。

- 文档中包含`<SCRIPT> `标签时的情况。因为无论是 DOM 或者 CSSOM 都可以被 JavaScript 所访问并修改，所以一旦在页面解析时遇到 `<SCRIPT>` 标签，DOM 的构造过程就会暂停，等待服务器请求脚本。在脚本加载完成后，还要等取回所有的 CSS 及完成 CSSOM 之后才继续执行。

  外部脚本的加载时机一定要确定好，能够延迟加载就选用延迟加载。另外，可以通过使用 defer 和 async，告诉浏览器在等待脚本下载期间不阻止解析过程，这样做可以明显提升性能。
  


#### 布局中的瓶颈点

浏览器会根据样式解析器给出的样式规则，来计算某个元素需要占据的空间大小和屏幕中的位置（比如图片的高度、宽度和位置），来进行布局。主线程布局时，使用的是流模型的布局方式。所谓流模型，就是像水流一样，需要从左到右，从上到下遍历一遍所有元素。

假设在页面**渲染过程运行的时候**修改了一个元素的属性，比如在电商的商品详情页加入一条广告数据。这时布局阶段受到了影响。浏览器必须检查所有其他区域的元素，然后自动重排页面，受到影响的元素需要重新绘制，最后还得合成，相当于整个渲染流程再来了一遍。

除此之外，因为浏览器每次布局计算都要作用于整个 DOM，如果元素量大，计算出所有元素的位置和尺寸会花很长的时间。所以布局阶段很容易成为性能瓶颈点。



页面加载全过程很复杂，在这里，主要介绍了前端领域能改变的瓶颈点，还有其他方面。比如，偏硬件领域，像 GPU 绘图、操作系统 GUI 和 LCD 显示等瓶颈点；网络层和服务层，如拥塞预防、负载均衡和慢启动；还有一些页面解析和渲染的算法，如解析算法、标记化算法和树构建算法等。

