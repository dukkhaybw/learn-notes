# 计算机操作系统

## 概述

为什么要学习操作系统？

什么是操作系统？

怎样学习操作系统？

学习操作系统需要的前导知识

操作系统：

从功能来区分，有对上和对下之分。

对上的话是面向用户或者应用系统，并为他们提供服务。从用户的角度看，操作系统是一个控制程序，可以控制计算机上面的一些应用软件和程序如何运行，为不同应用程序分配系统资源。另一方面，操作系统还为应用程序提供 I/O，网卡访问等一系列的能力。

对下的话给它管理的应用程序分配硬件资源，管理外设。

![image-20210808155915531](..\typora-user-images\image-20210808155915531.png)

操作系统是一种特殊的软件， 系统软件，它直接面向硬件。一般的应用程序实现的功能其实是操作系统提供的，并不是直接去访问物理资源（各种外设）。而这些外设资源是由操作系统统一协调管理，为一般应用程序提供接口 API，一般应用程序方便的访问这些接口，而不用考虑底层的硬件细节。

操作系统层面的软件有两种不同的对外的接口，Shell 和 kernel 。

![image-20210808161028100](..\typora-user-images\image-20210808161028100.png)

操作系统内部细节：

- CPU
  - CPU 调度
  - 进程与线程管理
- 内存
  - 物理内存管理
  - 虚拟内存管理，它主要是给上层应用提供相对独立且尽可能充足的空间去管理
- 磁盘
  - 文件系统管理
- 中断处理和 I/O，设备驱动
- 网卡
- 声卡
- 显卡
- ......

操作系统的特征：

- 并发，计算机系统中同时存在多个运行的程序，需要 OS 管理和调度哪个程序占用 CPU 去运行。并发：**一段时间**内有多个程序可以运行。 并行：**一个时间点**上有多个程序可以运行

  能并行任务一般要求系统存在多个 CPU。

- 共享，‘同时’共享和互斥共享

- 虚拟

- 异步

## CPU

关于底层细节，适度打开。

计算机需要解决的的最根本的问题：如何表示数字。

CPU 最主要的运算单位：晶体管。

时钟发生器不断通过 CPU 的针脚给 CPU 芯片局部通电和断电。程序需要计算的信号内容通过针脚不断输入 CPU 中，以前手工输入，另一种是将数据提前写好，并存在内存中，让 CPU 自己去读取。

内存的本质是在内部存放一系列的电信号，而这些电信号通过总线和 CPU 连接，CPU 将内存中的 1 和 0 读取后，在自己内部进行计算，这个计算过程需要通过时钟发生器不断的驱动它的通断电来实现。

CPU 一次性能读取 64 位二进制数据的话就是 64 位 CPU 系统。32 位同理。

CPU 只认识高电频低电频（0 与 1），对计算机进行输入就是控制针脚的通断电。最早的计算输入是纸袋机输入。

![image-20210808140613210](..\typora-user-images\image-20210808140613210.png)

## 汇编语言

汇编的本质：机器语言的助记符，本质就是机器语言。

解释与编译：

开发者写了一个程序（C 语言编写），位于硬盘上，需要执行时放在内存中，编译完的代码（.ELE，.EXE 等）直接就是机器语言，CPU 可以直接获取并执行。这就叫编译执行。

对于 Java 程序，在内存中是字节码（ByteCode），它是不能被 CPU 直接执行的，在执行的过程中是读取一条指令，交给 jvm 翻译为机器语言再交给 CPU 去执行的。这就叫解释执行。JVM 就是解释器。

机器语言和 ByteCode 都是用 0101 之类的表示的， 在 java 中 ByteCode 相当于 java 的汇编语言，因为 Java 跨平台。java 的汇编并不和具体的某个操作系统相关，因为 Java 是跨平台的。所以 java 就设计了一种中间格式 ByteCode，同一个指令由不同操作系统下的 Jvm 翻译都是不同的机器语言。

## CPU 基本组成

![image-20210808143352892](..\typora-user-images\image-20210808143352892.png)

**PC（program counter）**：程序计数器，记录存放当前来自内存的指令在内存中的地址（这条指令位于内存中的什么位置）。CPU 要执行下一条指令时，肯定需要知道下一条指令在内存中的位置。CPU 执行完一条指令地址对应的指令后，会切换为下一条指令，下一条指令并不一定是指令地址数组索引加一，因为指令的长度是不固定的，得看当前指令占的字节数。

内存是一块特别大的字节数组。

**Registers**：暂时存储 CPU 计算需要用到的数据（寄存器数量非常多，每个寄存器都有各自的用途），将读进 CPU 的数据先存在寄存器中，不能放在内存中，因为太慢了，而选择放在 CPU 内部。

**ALU（Arithmetic & Logic Unit）**:运算单元

**CU（Control Unit）**：控制单元，对中断信号的控制

**MMU（Memory Management Unit）**：内存管理单元

**cache**

![image-20210808151322196](..\typora-user-images\image-20210808151322196.png)

一核多线程：即一个运算单元对应多组寄存器。平时有一个线程要运行时，该线程相关的数据放在寄存器中，指令存在程序计数器中。

如果 CPU 中只有一组寄存器和 PC（程序计数器），在 thread1 运行中，thread2 线程要运行，就必须将寄存器和 PC 中的 thread1 相关数据取出去放在缓存中，然后将 thread2 的数据放入并执行，当线程 thread2 的运行时间片够了，再将寄存器和 PC 中的 thread2 相关数据取出去放在缓存中，在同样的过程恢复对 thread1 的执行。上面的过程就叫线程切换（context switch）。

<img src="..\typora-user-images\image-20210808153332302.png" alt="image-20210808153332302" style="zoom:200%;" />

补充：

内存中的数据如何给显卡？

CPU 发出指令，控制内存中的数据通过内存直接写给显卡（DMA 机制），并不是说内存中的数据都需要先交给 CPU，再由 CPU 去分发。内存中的数据发送给显卡后，显卡中的缓存区中的数据对应显示器中的像素。显示器自身有一个刷新率（60Hz，120Hz 等），刷新率表述每秒从显卡中读取缓存区数据进行刷新的次数。

GPU 为什么比 CPU 更适合做机器学习？

GPU 比较纯粹，就是做一些计算然后输出到显卡，而 CPU 做的是通用计算，所以 CPU 内部的电路优化是针对通用计算和普通计算的。CPU 对于人工智能所需要的哪些特殊的，大量的，计算类型不一样的计算并没有做优化。GPU 正好更适合于 AI 的算法上的优化。

AI 芯片：指的是在电路底层在设计时就设计为更适合 AI 计算的。

为什么要有缓存？

因为从 CPU 到不同的部件的速度不同。

![image-20210808153455187](..\typora-user-images\image-20210808153455187.png)

缓存的原理：

![image-20210808153641239](..\typora-user-images\image-20210808153641239.png)

![image-20210808153620913](..\typora-user-images\image-20210808153620913.png)

CPU 的乱序执行：CPU 在进行读等待的同时执行指令，能提高效率。

## 前言

- 操作系统级别的项目才是真正巨型的项目
- 内存泄漏，服务进程问题
- 操作系统是所有软件的基础，所有上层软件都要依赖于操作系统提供的各种机制来运行
- 内存、进程、线程、I/O 知识在工作中常用
- 性能调优
- 操作系统内核
- 数据结构与算法
- 架构视野、技术成长
- 理解操作系统内核的本质
- 每个内核组件实现

操作系统的难点：

- 需要有大量的知识储备，大多的课程、学习资料，往往都是根据目前已有的一些操作系统，做局部解读。所以，我们学的时候，前后的知识是无法串联在一起的。结果就会越看越迷惑，不去查吧，看不懂，再去搜索又加重了学习负担。

安排：

1. 计算机组成，如 CPU、MMU、内存和 Cache 等
2. 基本法，即各种同步机制，如信号量与自旋锁
3. 初始化，其中包含初始化 CPU、内存、中断、显示等
4. 建立中间层，内存管理部门、进程管理部门、I/O 管理部门、文件管理部门、通信管理部门
5. 组合中间层为操作系统

![img](https://static001.geekbang.org/resource/image/d6/d9/d68f8a262c1582f04377476f9ed9yyd9.jpg?wh=3145*2404)

![img](https://static001.geekbang.org/resource/image/5f/cf/5fbeyy963478d11db45da0dd3e8effcf.jpg?wh=3245*2265)

1. 写出一个操作系统
2. 深入理解 Linux 操作系统
3. 操作系统架构设计能力
4. 软件编程技巧
5. 辅助职业发展

![img](https://static001.geekbang.org/resource/image/2c/bd/2c6abcd035e5c83cdd7d356eca26b9bd.jpg?wh=6120*6599)

**对于工程师来说，树高叶茂，系于根深，只有不断升级自己的认知，才能让技术之路行稳致远。**

## 程序的运行过程

从高级语言到机器代码再到程序运行。

**程序是如何运行的？**

注重编程基本功和程序开发经验。

对于一段 c 语言写的程序：

HelloWorld.c：

```c
#include "stdio.h"
int main(int argc, char const *argv[])
{
  printf("Hello World!\n");
  return 0;
}
```

计算机硬件是无法直接运行这个 C 语言代码程序的，需要 **C 语言编译器**，把这个代码编译成**具体硬件平台**的二进制代码。再由**具体操作系统建立进程**，把编译生成的二进制文件装进其进程的内存空间中，才能运行。

### 编译过程

使用命令：gcc HelloWorld.c -o HelloWorld 或者 gcc ./HelloWorld.c -o ./HelloWorld，编译上面的代码。

GCC 是完成编译工作的**驱动程序**，它会根据编译流程分别调用预处理程序、编译程序、汇编程序、链接程序来完成具体工作。

![img](https://static001.geekbang.org/resource/image/f2/4a/f2b10135ed52436888a793327e4d5a4a.jpg?wh=3015*2410)

手动控制以上这个编译流程，从而留下中间文件：

- gcc HelloWorld.c -E -o HelloWorld.i 预处理：加入头文件，替换宏。
- gcc HelloWorld.c -S -c -o HelloWorld.s 编译：包含预处理，将 C 程序转换成汇编程序。
- gcc HelloWorld.c -c -o HelloWorld.o 汇编：包含预处理和编译，将汇编程序转换成可链接的二进制程序。
- gcc HelloWorld.c -o HelloWorld 链接：包含以上所有操作，将可链接的二进制程序和其它别的库链接在一起，形成可执行的程序文件。

上面准备好了 CPU 将要执行的二进制机器码。

### 硬件执行程序过程

开始程序的装载执行。

#### 图灵机

图灵机：是一个抽象的模型，它是这样的：有一条无限长的纸带，纸带上有无限个小格子，小格子中写有相关的信息，纸带上有一个读头，读头能根据纸带小格子里的信息做相关的操作并能来回移动。

![image-20220826164254509](.\typora-user-images\image-20220826164254509.png)

用图灵机执行一下“1+1=2”的计算，定义读头读到“+”之后，就依次移动读头两次并读取格子中的数据，最后读头计算把结果写入第二个数据的下一个格子里，整个过程如下图：

![image-20220826164408197](.\typora-user-images\image-20220826164408197.png)

#### 冯诺依曼体系结构

实现图灵机。**电子计算机使用二进制数制系统和储存程序，并按照程序顺序执行。**

根据冯诺依曼体系结构构成的计算机，必须具有如下功能：

1. 把程序和数据装入到计算机中；
2. 必须具有长期记住程序、数据的中间结果及最终运算结果的能力；
3. 能完成各种算术、逻辑运算和数据传送等数据加工处理；
4. 根据需要控制程序走向，并能根据指令控制机器的各部件协调操作；
5. 能够按照要求将处理的数据结果显示给用户。

为了完成上述的功能，计算机必须具备五大基本组成部件：

1. 承载数据和程序的输入设备；
2. 记录与存放程序和数据的存储器；
3. 进行数据加工处理的运算器；
4. 控制程序执行的控制器；
5. 显示处理结果的输出设备。

根据冯诺依曼的理论，只要把图灵机的几个部件换成电子设备，就可以变成一个最小核心的电子计算机，如下图：

![image-20220826165744096](.\typora-user-images\image-20220826165744096.png)

读头不再来回移动了，而是靠地址总线寻找对应的“纸带格子”。读取写入数据由数据总线完成，而动作的控制就是控制总线的职责。

#### HelloWorld 程序中有什么

通过 gcc -c -S HelloWorld 得到汇编代码（只能得到其汇编代码）。用 objdump -d HelloWorld 程序，得到 /lesson01/HelloWorld.dump，其中有很多库代码（只需关注 main 函数相关的代码），如下图：

![image-20220826170608042](.\typora-user-images\image-20220826170608042.png)

以上图中，分成四列：第一列为地址；第二列为十六进制，表示真正装入机器中的代码数据；第三列是对应的汇编代码；第四列是相关代码的注释。这是 x86_64 体系的代码，由此可以看出 x86 CPU 是变长指令集。

把这段代码数据装入最小电子计算机，状态如下图：

![image-20220826170947946](.\typora-user-images\image-20220826170947946.png)

现代电子计算机正是通过内存中的信息（指令和数据）做出相应的操作，并通过内存地址的变化，达到程序读取数据，控制程序流程（顺序、跳转对应该图灵机的读头来回移动）的功能。

这和图灵机的核心思想相比，没有根本性的变化。只要配合一些 I/O 设备，让用户输入并显示计算结果给用户，就是一台现代意义的电子计算机。

提问：

**为了实现 C 语言中函数的调用和返回功能，CPU 实现了函数调用和返回指令，即上图汇编代码中的“call”，“ret”指令**，思考一下：call 和 ret 指令在逻辑上执行的操作是怎样的呢？

> 思考题:
>
> 首先假设 CPU 执行指令是按照顺序执行的，那么程序的指令的调用需要考虑几个问题:
>
> 1，call 指令要执行的代码在哪？也就是被调用函数的第一条指令所在的内存地址
>
> 2，被调用函数执行完之后，返回哪个位置继续执行？
>
> 只要解决上面这两个问题，那么函数调用时指令间的跳转就迎刃而解了。
>
> 针对第一个问题，在 gcc 编译完成之后，函数对应的指令序列所在的位置就已经确定了，因此这是编译阶段需要考虑的问题
>
> 第二个问题，在执行完 call 指令的同时，需要将 call 指令下面一条指令的地址保存到栈内存中，同时更新%rsp 寄存器指向的位置，然后就可以开始执行被调函数的指令序列，执行完毕后，由 ret 指令从 rsp 中获取栈顶的 return adress 地址，然后跳转到 call 的下一条指令继续执行。

> call 和 ret 其实是一对相反指令，调用 call 时会将当前 IP 入栈，即 push IP，然后执行跳转即 jmp，而 ret 也是将栈中的 IP 推出写入 IP 寄存器，即 pop IP。
>
> call 指令会把当前的 PC(CS:IP) 寄存器里的下一条指令的地址压栈，然后进行 JMP 跳转指令； ret 指令则把 call 调用时压入的 PC 寄存器里的下一条指令出栈，更新到 PC 寄存器中

王爽的《汇编语言》
